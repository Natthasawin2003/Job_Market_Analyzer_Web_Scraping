================================================================
บทที่ 4 วิธีการพัฒนาระบบ (ส่วน Dashboard — Streamlit)
================================================================

ระบบ Dashboard พัฒนาด้วย Streamlit ทำหน้าที่อ่านข้อมูลที่ดึงมาจาก
ระบบ Web Scraping แล้วแสดงผลในรูปแบบกราฟและตารางแบบ Interactive
ผู้ใช้สามารถกรองข้อมูลผ่าน Sidebar และดาวน์โหลดข้อมูลที่กรองแล้วได้

----------------------------------------------------------------
4.6 การตั้งค่าและนำเข้าไลบรารี (Setup & Imports)
----------------------------------------------------------------

นำเข้าไลบรารีที่ใช้สร้าง Dashboard และแสดงผลกราฟ

    import streamlit as st          # Web App Framework
    import pandas as pd             # จัดการข้อมูลตาราง
    import plotly.express as px     # กราฟ Interactive
    import matplotlib.pyplot as plt # กราฟพื้นฐาน
    import json                     # อ่านไฟล์ GeoJSON แผนที่
    from pathlib import Path        # จัดการเส้นทางไฟล์
    import re, datetime


ตั้งค่าหน้าเพจให้แสดงแบบ Wide Layout และกำหนดฟอนต์สำหรับกราฟ
ให้รองรับภาษาไทย

    st.set_page_config(layout="wide")
    plt.rcParams["font.family"] = "Tahoma"   # ฟอนต์รองรับภาษาไทย


ฉีด CSS แบบกำหนดเองเพื่อตกแต่งหน้าตา Dashboard เช่น
สีพื้นหลัง, การ์ด Metric, Sidebar และ Hover Animation

    st.markdown("""
    <style>
        .stApp           { background-color: #f8fafc; }
        [data-testid="stSidebar"] { background-color: #e2e8f0; }
        [data-testid="stMetric"] {
            background: #ffffff;
            border-radius: 14px;
            box-shadow: 0 6px 18px rgba(15,23,42,0.08);
        }
        [data-testid="stMetric"]:hover {
            transform: translateY(-4px);   /* ยกการ์ดขึ้นเมื่อ Hover */
            transition: 0.2s;
        }
        ...
    </style>
    """, unsafe_allow_html=True)


----------------------------------------------------------------
4.7 การโหลดและเตรียมข้อมูล (Data Loading & Preprocessing)
----------------------------------------------------------------

อ่านไฟล์ CSV ที่ระบบ Web Scraping ส่งออกมา แล้วคำนวณ
ค่ากลางของเงินเดือน (mid_salary) จากขั้นต่ำ-ขั้นสูง

    df = pd.read_csv(".../Scraped_All/jobs_all_scraped.csv")

    # คำนวณเงินเดือนกลาง โดยเฉลี่ย min_salary และ max_salary
    df["mid_salary"] = df[["min_salary", "max_salary"]].mean(axis=1)

    # แปลงคอลัมน์วันที่ให้เป็น datetime สำหรับการกรองและการแสดงผล
    df["posted_date"] = pd.to_datetime(df["posted_date"], errors="coerce")


ฟังก์ชันตรวจหาวันที่ดึงข้อมูลล่าสุดจาก Timestamp ในชื่อไฟล์
เพื่อแสดงบน Title ของ Dashboard

    def get_latest_scrape_datetime_text(scraped_dir: Path) -> str:
        date_pattern = re.compile(r"(\d{8})(?:_(\d{6}))?")
        latest_dt = None

        for csv_path in scraped_dir.glob("*.csv"):    # วนซ้ำทุกไฟล์ CSV
            match = date_pattern.search(csv_path.stem)
            if not match:
                continue

            date_part = match.group(1)
            time_part = match.group(2) or "000000"

            current_dt = datetime.datetime.strptime(
                f"{date_part}{time_part}", "%Y%m%d%H%M%S"
            )

            if latest_dt is None or current_dt > latest_dt:
                latest_dt = current_dt                # เก็บวันที่ล่าสุด

        return f"Latest update: {latest_dt:%Y-%m-%d %H:%M}" if latest_dt else "N/A"


----------------------------------------------------------------
4.8 Sidebar Filters (ตัวกรองข้อมูลด้านข้าง)
----------------------------------------------------------------

Sidebar ประกอบด้วยตัวกรองหลายประเภท ทั้ง text, checkbox,
number input, date range, slider และ selectbox โดยทุก widget
ผูกกับ session_state เพื่อให้ปุ่ม Reset ทำงานได้

    def reset_filters():
        # รีเซ็ตทุก key ใน session_state กลับสู่ค่าเริ่มต้น
        st.session_state["keyword_filter"]   = ""
        st.session_state["use_salary_filter"] = False
        st.session_state["province_filter"]  = "All"
        st.session_state["web_filter"]       = "All"
        ...

    st.sidebar.button("Reset Filters", on_click=reset_filters)

    keyword    = st.sidebar.text_input("Search job",        key="keyword_filter")
    use_salary = st.sidebar.checkbox("Filter by salary",    key="use_salary_filter")
    date_range = st.sidebar.date_input("Posted date range", key="date_range_filter")
    top_skill_n = st.sidebar.slider("Top skills in treemap", 5, skill_slider_max, 12)
    province   = st.sidebar.selectbox("Province", province_list, key="province_filter")
    web        = st.sidebar.selectbox("Website",  web_list,      key="web_filter")


ตัวกรองถูกนำไปกรอง DataFrame จริงด้วย Boolean Indexing

    if keyword:
        df = df[df["keyword"].str.contains(keyword, case=False, na=False)]

    if province != "All":
        df = df[df["province_name"] == province]

    if use_salary:
        df = df[(df["max_salary"].isna()) | (df["max_salary"] >= salary)]


----------------------------------------------------------------
4.9 การแสดงผล Metric Cards (กล่องตัวเลขสรุป)
----------------------------------------------------------------

แสดงตัวเลขสรุปด้านบนสุดของ Dashboard ใน 4 คอลัมน์

    c1, c2, c3, c4 = st.columns(4)

    c1.metric("Total Jobs",  len(df_show))              # จำนวนงานทั้งหมด

    avg = df_show["mid_salary"].mean()
    c2.metric("Avg Salary",
              f"{int(avg):,}" if pd.notna(avg) else "0") # ค่าเฉลี่ยเงินเดือน

    c3.metric("Companies", df_show["company"].nunique()) # จำนวนบริษัท

    percent = df_show["mid_salary"].notna().sum() / len(df_show) * 100
    c4.metric("Show Salary", "%.1f %%" % percent)       # % งานที่บอกเงินเดือน


----------------------------------------------------------------
4.10 การแสดงผลกราฟ (Charts)
----------------------------------------------------------------

แบ่ง Layout เป็น 2 แถว รวม 5 กราฟ โดยใช้ st.columns()
แบ่งพื้นที่แต่ละกราฟ

---- กราฟแท่ง: ช่วงเงินเดือน (Salary Range Bar Chart) ----

    bins   = [0, 25000, 50000, 75000, 100000, 125000, 150000, 1000000]
    labels = ["<25k", "25-50k", "50-75k", ...]

    # จัดกลุ่มเงินเดือนกลางเป็นช่วง ด้วย pd.cut()
    temp["ช่วงเงินเดือน"] = pd.cut(temp["mid_salary"], bins=bins, labels=labels)

    counts = temp["ช่วงเงินเดือน"].value_counts().sort_index()
    st.bar_chart(counts, color="#4f46e5", height=420)


---- กราฟ Sunburst: สัดส่วนงานต่อเว็บไซต์และตำแหน่ง ----

    fig_web = px.sunburst(
        web_keyword_counts,
        path=["Website", "Keyword"],   # แสดง 2 ระดับ: เว็บไซต์ → ตำแหน่งงาน
        values="Jobs",
        color="Website",
    )
    st.plotly_chart(fig_web, use_container_width=True)


---- กราฟ Choropleth Map: จำนวนงานต่อจังหวัด ----

ระบบโหลด GeoJSON ของแผนที่ประเทศไทย แล้ว Merge กับจำนวนงาน
ต่อจังหวัดก่อนส่งให้ Plotly วาดแผนที่สี

    # โหลดไฟล์ GeoJSON แผนที่ประเทศไทย
    with open("Tle/thailand.json", encoding="utf-8") as f:
        geo = json.load(f)

    # นับจำนวนงานต่อจังหวัด แล้ว merge กับชื่อจังหวัดใน GeoJSON
    province_counts = (
        pd.DataFrame({"province": geo_names})
        .merge(df_show["province_eng"].value_counts().reset_index(), on="province", how="left")
        .fillna(0)
    )

    fig = px.choropleth(
        province_counts,
        geojson=geo,
        locations="province",
        featureidkey="properties.name",   # เชื่อม DataFrame กับ GeoJSON property
        color="jobs",
        color_continuous_scale="PuBu",
    )

    fig.update_geos(fitbounds="locations", visible=False)
    st.plotly_chart(fig, use_container_width=True)


---- กราฟ Treemap: ทักษะที่ต้องการมากที่สุด ----

    skill_cols   = [c for c in df_show.columns if c.startswith("skill_")]
    skill_counts = df_show[skill_cols].sum().sort_values(ascending=False)
    skill_counts = skill_counts.head(top_skill_n)   # แสดงตามจำนวนที่เลือกใน Slider

    # แปลงชื่อคอลัมน์ เช่น "skill_machine_learning" → "Machine Learning"
    skill_counts.index = [
        str(name).replace("skill_", "").replace("_", " ").capitalize()
        for name in skill_counts.index
    ]

    fig2 = px.treemap(
        skill_counts.reset_index(),
        path=["Skill"],
        values="Count",
        color="Count",
        color_continuous_scale="PuBuGn",
    )
    st.plotly_chart(fig2, use_container_width=True)


----------------------------------------------------------------
4.11 ตารางข้อมูลงานและการดาวน์โหลด (Job Table & Download)
----------------------------------------------------------------

แสดงข้อมูลงานที่กรองแล้วในตาราง พร้อมปุ่มดาวน์โหลด CSV

    # เรียงลำดับตามวันที่โพสต์ล่าสุด
    table_df = (
        table_df.assign(_posted_sort=pd.to_datetime(table_df["Posted Date"], errors="coerce"))
        .sort_values("_posted_sort", ascending=False)
        .drop(columns=["_posted_sort"])
    )

    # ปุ่มดาวน์โหลดไฟล์ CSV พร้อม Timestamp ในชื่อไฟล์
    download_name = f"filtered_jobs_{datetime.datetime.now():%Y%m%d_%H%M%S}.csv"
    st.download_button(
        "Download filtered data (CSV)",
        data=table_df.to_csv(index=False).encode("utf-8-sig"),
        file_name=download_name,
        mime="text/csv",
    )

    # แสดงตาราง โดยคอลัมน์ Link เป็น Clickable Link
    column_config = {
        "Link": st.column_config.LinkColumn("Link", display_text="open job")
    }

    st.dataframe(
        table_df,
        use_container_width=True,
        height=420,
        hide_index=True,
        column_config=column_config,   # กำหนดรูปแบบคอลัมน์พิเศษ
    )

================================================================
