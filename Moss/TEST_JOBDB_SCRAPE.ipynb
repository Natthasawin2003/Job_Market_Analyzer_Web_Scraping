{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9be0a993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Search] Starting JobsDB crawl: max_pages=10\n",
      "[Search] Page 1/10 -> request\n",
      "[Search] Page 1/10 -> found cards: 32\n",
      "[Search] Page 1/10 -> kept 24 | cumulative=24\n",
      "[Search] Page 2/10 -> request\n",
      "[Search] Page 2/10 -> found cards: 32\n",
      "[Search] Page 2/10 -> kept 14 | cumulative=38\n",
      "[Search] Page 3/10 -> request\n",
      "[Search] Page 3/10 -> found cards: 32\n",
      "[Search] Page 3/10 -> kept 12 | cumulative=50\n",
      "[Search] Page 4/10 -> request\n",
      "[Search] Page 4/10 -> found cards: 32\n",
      "[Search] Page 4/10 -> kept 6 | cumulative=56\n",
      "[Search] Page 5/10 -> request\n",
      "[Search] Page 5/10 -> found cards: 32\n",
      "[Search] Page 5/10 -> kept 5 | cumulative=61\n",
      "[Search] Page 6/10 -> request\n",
      "[Search] Page 6/10 -> found cards: 32\n",
      "[Search] Page 6/10 -> kept 2 | cumulative=63\n",
      "[Search] Page 7/10 -> request\n",
      "[Search] Page 7/10 -> found cards: 32\n",
      "[Search] Page 7/10 -> kept 3 | cumulative=66\n",
      "[Search] Page 8/10 -> request\n",
      "[Search] Page 8/10 -> found cards: 32\n",
      "[Search] Page 8/10 -> kept 1 | cumulative=67\n",
      "[Search] Page 9/10 -> request\n",
      "[Search] Page 9/10 -> found cards: 32\n",
      "[Search] Page 9/10 -> no keyword matches, stopping\n",
      "[Detail] Start detail scrape for 67 jobs\n",
      "[Detail] 10/67 (14.9%)\n",
      "[Detail] 20/67 (29.9%)\n",
      "[Detail] 30/67 (44.8%)\n",
      "[Detail] 40/67 (59.7%)\n",
      "[Detail] 50/67 (74.6%)\n",
      "[Detail] 60/67 (89.6%)\n",
      "[Detail] 67/67 (100.0%)\n",
      "\n",
      "Total unique jobs: 67\n",
      "Saved to: G:\\Users\\Moss\\Documents\\PYTHON_PROJECT\\Job_Market_Analyzer_Web_Scraping\\Moss\\jobsdb_data-analyst_20260217.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>province_code</th>\n",
       "      <th>province_name</th>\n",
       "      <th>page</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>job_url</th>\n",
       "      <th>...</th>\n",
       "      <th>skill_docker</th>\n",
       "      <th>skill_kubernetes</th>\n",
       "      <th>skill_mlflow</th>\n",
       "      <th>skill_fastapi</th>\n",
       "      <th>skill_flask</th>\n",
       "      <th>skill_streamlit</th>\n",
       "      <th>skill_statistics</th>\n",
       "      <th>skill_git</th>\n",
       "      <th>skill_api</th>\n",
       "      <th>skill_linux</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data analyst</td>\n",
       "      <td></td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Protech Transfer Co., Ltd.</td>\n",
       "      <td>ยานนาวา กรุงเทพมหานคร</td>\n",
       "      <td></td>\n",
       "      <td>6 ชั่วโมงที่ผ่านมา</td>\n",
       "      <td>https://th.jobsdb.com/th/job/90386899?type=sta...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data analyst</td>\n",
       "      <td></td>\n",
       "      <td>ปทุมธานี</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>SAPPE PUBLIC COMPANY LIMITED</td>\n",
       "      <td>ลำลูกกา ปทุมธานี</td>\n",
       "      <td></td>\n",
       "      <td>1 ชั่วโมงที่ผ่านมา</td>\n",
       "      <td>https://th.jobsdb.com/th/job/90392072?type=sta...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data analyst</td>\n",
       "      <td></td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Claim Analyst (Motor Claim)</td>\n",
       "      <td>Krungthai Panich Insurance Public Company Limited</td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td></td>\n",
       "      <td>5 ชั่วโมงที่ผ่านมา</td>\n",
       "      <td>https://th.jobsdb.com/th/job/90387373?type=sta...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data analyst</td>\n",
       "      <td></td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst /Operations Report /Customer Care...</td>\n",
       "      <td>Cartrack SEA</td>\n",
       "      <td>บางนา กรุงเทพมหานคร</td>\n",
       "      <td></td>\n",
       "      <td>1 วันที่ผ่านมา</td>\n",
       "      <td>https://th.jobsdb.com/th/job/89813394?type=sta...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data analyst</td>\n",
       "      <td></td>\n",
       "      <td>ระยอง</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analysis &amp; Performance Engineer</td>\n",
       "      <td>PURAC (Thailand) Ltd.</td>\n",
       "      <td>ระยอง</td>\n",
       "      <td></td>\n",
       "      <td>37 นาทีที่ผ่านมา</td>\n",
       "      <td>https://th.jobsdb.com/th/job/90392644?type=sta...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data analyst</td>\n",
       "      <td></td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Focus Media (Thailand) Co., Ltd.</td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td></td>\n",
       "      <td>6 วันที่ผ่านมา</td>\n",
       "      <td>https://th.jobsdb.com/th/job/90278961?type=sta...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data analyst</td>\n",
       "      <td></td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst – Business Decision &amp; Data Quality</td>\n",
       "      <td>Maybank Securities (Thailand) Public Company L...</td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td></td>\n",
       "      <td>21 วันที่ผ่านมา</td>\n",
       "      <td>https://th.jobsdb.com/th/job/89949693?type=sta...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data analyst</td>\n",
       "      <td></td>\n",
       "      <td>นนทบุรี</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst (Fraud Management)</td>\n",
       "      <td>Triple T Broadband Public Company Limited</td>\n",
       "      <td>ปากเกร็ด นนทบุรี</td>\n",
       "      <td></td>\n",
       "      <td>3 วันที่ผ่านมา</td>\n",
       "      <td>https://th.jobsdb.com/th/job/90337958?type=sta...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data analyst</td>\n",
       "      <td></td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>GMM Grammy Public Company Limited</td>\n",
       "      <td>วัฒนา กรุงเทพมหานคร</td>\n",
       "      <td></td>\n",
       "      <td>5 วันที่ผ่านมา</td>\n",
       "      <td>https://th.jobsdb.com/th/job/90297020?type=sta...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data analyst</td>\n",
       "      <td></td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst (Food Business)</td>\n",
       "      <td>Central Group (Central Pattana Public Company ...</td>\n",
       "      <td>ปทุมวัน กรุงเทพมหานคร</td>\n",
       "      <td></td>\n",
       "      <td>19 วันที่ผ่านมา</td>\n",
       "      <td>https://th.jobsdb.com/th/job/90012046?type=sta...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>data analyst</td>\n",
       "      <td></td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>1</td>\n",
       "      <td>Commercial Data Analyst (1-3 yrs.) under Comme...</td>\n",
       "      <td>Berlin Pharmaceutical Industry Co., Ltd.</td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td></td>\n",
       "      <td>18 วันที่ผ่านมา</td>\n",
       "      <td>https://th.jobsdb.com/th/job/90031204?type=sta...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>data analyst</td>\n",
       "      <td></td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>1</td>\n",
       "      <td>เจ้าหน้าที่วิเคราะห์ข้อมูล (MIS/Data Analyst)</td>\n",
       "      <td>Muang Thai Life Assurance Public Company Limited</td>\n",
       "      <td>ห้วยขวาง กรุงเทพมหานคร</td>\n",
       "      <td></td>\n",
       "      <td>11 วันที่ผ่านมา</td>\n",
       "      <td>https://th.jobsdb.com/th/job/90163043?type=sta...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>data analyst</td>\n",
       "      <td></td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>1</td>\n",
       "      <td>Business Analyst (Regulatory Data)</td>\n",
       "      <td>Bank of Ayudhya Public Company Limited</td>\n",
       "      <td>ยานนาวา กรุงเทพมหานคร</td>\n",
       "      <td></td>\n",
       "      <td>4 วันที่ผ่านมา</td>\n",
       "      <td>https://th.jobsdb.com/th/job/90334018?type=sta...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>data analyst</td>\n",
       "      <td></td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst (Executive Support)</td>\n",
       "      <td>Master Style Public Company Limited</td>\n",
       "      <td>ดุสิต กรุงเทพมหานคร</td>\n",
       "      <td></td>\n",
       "      <td>5 วันที่ผ่านมา</td>\n",
       "      <td>https://th.jobsdb.com/th/job/90300290?type=sta...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>data analyst</td>\n",
       "      <td></td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>1</td>\n",
       "      <td>Fraud Data Analyst</td>\n",
       "      <td>Ascend Money Group</td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td></td>\n",
       "      <td>27 วันที่ผ่านมา</td>\n",
       "      <td>https://th.jobsdb.com/th/job/89830956?type=sta...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>data analyst</td>\n",
       "      <td></td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>1</td>\n",
       "      <td>Business Intelligence &amp; Data Analytics</td>\n",
       "      <td>PTG Energy Public Company Limited</td>\n",
       "      <td>ห้วยขวาง กรุงเทพมหานคร</td>\n",
       "      <td></td>\n",
       "      <td>4 วันที่ผ่านมา</td>\n",
       "      <td>https://th.jobsdb.com/th/job/90310949?type=sta...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>data analyst</td>\n",
       "      <td></td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>RERMMAI CO., LTD.</td>\n",
       "      <td>สายไหม กรุงเทพมหานคร</td>\n",
       "      <td></td>\n",
       "      <td>19 วันที่ผ่านมา</td>\n",
       "      <td>https://th.jobsdb.com/th/job/89373734?type=sta...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>data analyst</td>\n",
       "      <td></td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst (Carrier Business)</td>\n",
       "      <td>Huawei Technologies (Thailand) Co., Ltd.</td>\n",
       "      <td>ห้วยขวาง กรุงเทพมหานคร</td>\n",
       "      <td></td>\n",
       "      <td>5 วันที่ผ่านมา</td>\n",
       "      <td>https://th.jobsdb.com/th/job/90306931?type=sta...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>data analyst</td>\n",
       "      <td></td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>1</td>\n",
       "      <td>Retail Marketing Analyst &amp; Data Intelligence (...</td>\n",
       "      <td>Charoen Pokphand Foods Public Company Limited</td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>฿55,000 – ฿75,000 per month</td>\n",
       "      <td>2 วันที่ผ่านมา</td>\n",
       "      <td>https://th.jobsdb.com/th/job/90346685?type=sta...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>data analyst</td>\n",
       "      <td></td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst, Data Scientist, Data Engineer</td>\n",
       "      <td>Land and Houses Bank Public Company Limited</td>\n",
       "      <td>สาทร กรุงเทพมหานคร</td>\n",
       "      <td></td>\n",
       "      <td>24 วันที่ผ่านมา</td>\n",
       "      <td>https://th.jobsdb.com/th/job/89901519?type=sta...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         keyword province_code  province_name  page  \\\n",
       "0   data analyst                กรุงเทพมหานคร     1   \n",
       "1   data analyst                     ปทุมธานี     1   \n",
       "2   data analyst                กรุงเทพมหานคร     1   \n",
       "3   data analyst                กรุงเทพมหานคร     1   \n",
       "4   data analyst                        ระยอง     1   \n",
       "5   data analyst                กรุงเทพมหานคร     1   \n",
       "6   data analyst                กรุงเทพมหานคร     1   \n",
       "7   data analyst                      นนทบุรี     1   \n",
       "8   data analyst                กรุงเทพมหานคร     1   \n",
       "9   data analyst                กรุงเทพมหานคร     1   \n",
       "10  data analyst                กรุงเทพมหานคร     1   \n",
       "11  data analyst                กรุงเทพมหานคร     1   \n",
       "12  data analyst                กรุงเทพมหานคร     1   \n",
       "13  data analyst                กรุงเทพมหานคร     1   \n",
       "14  data analyst                กรุงเทพมหานคร     1   \n",
       "15  data analyst                กรุงเทพมหานคร     1   \n",
       "16  data analyst                กรุงเทพมหานคร     1   \n",
       "17  data analyst                กรุงเทพมหานคร     1   \n",
       "18  data analyst                กรุงเทพมหานคร     1   \n",
       "19  data analyst                กรุงเทพมหานคร     1   \n",
       "\n",
       "                                            job_title  \\\n",
       "0                                        Data Analyst   \n",
       "1                                        Data Analyst   \n",
       "2                    Data Claim Analyst (Motor Claim)   \n",
       "3   Data Analyst /Operations Report /Customer Care...   \n",
       "4                Data Analysis & Performance Engineer   \n",
       "5                                        Data Analyst   \n",
       "6     Data Analyst – Business Decision & Data Quality   \n",
       "7                     Data Analyst (Fraud Management)   \n",
       "8                                        Data Analyst   \n",
       "9                        Data Analyst (Food Business)   \n",
       "10  Commercial Data Analyst (1-3 yrs.) under Comme...   \n",
       "11      เจ้าหน้าที่วิเคราะห์ข้อมูล (MIS/Data Analyst)   \n",
       "12                 Business Analyst (Regulatory Data)   \n",
       "13                   Data Analyst (Executive Support)   \n",
       "14                                 Fraud Data Analyst   \n",
       "15             Business Intelligence & Data Analytics   \n",
       "16                                       Data Analyst   \n",
       "17                    Data Analyst (Carrier Business)   \n",
       "18  Retail Marketing Analyst & Data Intelligence (...   \n",
       "19        Data Analyst, Data Scientist, Data Engineer   \n",
       "\n",
       "                                              company                location  \\\n",
       "0                          Protech Transfer Co., Ltd.   ยานนาวา กรุงเทพมหานคร   \n",
       "1                        SAPPE PUBLIC COMPANY LIMITED        ลำลูกกา ปทุมธานี   \n",
       "2   Krungthai Panich Insurance Public Company Limited           กรุงเทพมหานคร   \n",
       "3                                        Cartrack SEA     บางนา กรุงเทพมหานคร   \n",
       "4                               PURAC (Thailand) Ltd.                   ระยอง   \n",
       "5                    Focus Media (Thailand) Co., Ltd.           กรุงเทพมหานคร   \n",
       "6   Maybank Securities (Thailand) Public Company L...           กรุงเทพมหานคร   \n",
       "7           Triple T Broadband Public Company Limited        ปากเกร็ด นนทบุรี   \n",
       "8                   GMM Grammy Public Company Limited     วัฒนา กรุงเทพมหานคร   \n",
       "9   Central Group (Central Pattana Public Company ...   ปทุมวัน กรุงเทพมหานคร   \n",
       "10           Berlin Pharmaceutical Industry Co., Ltd.           กรุงเทพมหานคร   \n",
       "11   Muang Thai Life Assurance Public Company Limited  ห้วยขวาง กรุงเทพมหานคร   \n",
       "12             Bank of Ayudhya Public Company Limited   ยานนาวา กรุงเทพมหานคร   \n",
       "13                Master Style Public Company Limited     ดุสิต กรุงเทพมหานคร   \n",
       "14                                 Ascend Money Group           กรุงเทพมหานคร   \n",
       "15                  PTG Energy Public Company Limited  ห้วยขวาง กรุงเทพมหานคร   \n",
       "16                                  RERMMAI CO., LTD.    สายไหม กรุงเทพมหานคร   \n",
       "17           Huawei Technologies (Thailand) Co., Ltd.  ห้วยขวาง กรุงเทพมหานคร   \n",
       "18      Charoen Pokphand Foods Public Company Limited           กรุงเทพมหานคร   \n",
       "19        Land and Houses Bank Public Company Limited      สาทร กรุงเทพมหานคร   \n",
       "\n",
       "                         salary         posted_date  \\\n",
       "0                                6 ชั่วโมงที่ผ่านมา   \n",
       "1                                1 ชั่วโมงที่ผ่านมา   \n",
       "2                                5 ชั่วโมงที่ผ่านมา   \n",
       "3                                    1 วันที่ผ่านมา   \n",
       "4                                  37 นาทีที่ผ่านมา   \n",
       "5                                    6 วันที่ผ่านมา   \n",
       "6                                   21 วันที่ผ่านมา   \n",
       "7                                    3 วันที่ผ่านมา   \n",
       "8                                    5 วันที่ผ่านมา   \n",
       "9                                   19 วันที่ผ่านมา   \n",
       "10                                  18 วันที่ผ่านมา   \n",
       "11                                  11 วันที่ผ่านมา   \n",
       "12                                   4 วันที่ผ่านมา   \n",
       "13                                   5 วันที่ผ่านมา   \n",
       "14                                  27 วันที่ผ่านมา   \n",
       "15                                   4 วันที่ผ่านมา   \n",
       "16                                  19 วันที่ผ่านมา   \n",
       "17                                   5 วันที่ผ่านมา   \n",
       "18  ฿55,000 – ฿75,000 per month      2 วันที่ผ่านมา   \n",
       "19                                  24 วันที่ผ่านมา   \n",
       "\n",
       "                                              job_url  ... skill_docker  \\\n",
       "0   https://th.jobsdb.com/th/job/90386899?type=sta...  ...            0   \n",
       "1   https://th.jobsdb.com/th/job/90392072?type=sta...  ...            0   \n",
       "2   https://th.jobsdb.com/th/job/90387373?type=sta...  ...            0   \n",
       "3   https://th.jobsdb.com/th/job/89813394?type=sta...  ...            0   \n",
       "4   https://th.jobsdb.com/th/job/90392644?type=sta...  ...            0   \n",
       "5   https://th.jobsdb.com/th/job/90278961?type=sta...  ...            0   \n",
       "6   https://th.jobsdb.com/th/job/89949693?type=sta...  ...            0   \n",
       "7   https://th.jobsdb.com/th/job/90337958?type=sta...  ...            0   \n",
       "8   https://th.jobsdb.com/th/job/90297020?type=sta...  ...            0   \n",
       "9   https://th.jobsdb.com/th/job/90012046?type=sta...  ...            0   \n",
       "10  https://th.jobsdb.com/th/job/90031204?type=sta...  ...            0   \n",
       "11  https://th.jobsdb.com/th/job/90163043?type=sta...  ...            0   \n",
       "12  https://th.jobsdb.com/th/job/90334018?type=sta...  ...            0   \n",
       "13  https://th.jobsdb.com/th/job/90300290?type=sta...  ...            0   \n",
       "14  https://th.jobsdb.com/th/job/89830956?type=sta...  ...            0   \n",
       "15  https://th.jobsdb.com/th/job/90310949?type=sta...  ...            0   \n",
       "16  https://th.jobsdb.com/th/job/89373734?type=sta...  ...            0   \n",
       "17  https://th.jobsdb.com/th/job/90306931?type=sta...  ...            0   \n",
       "18  https://th.jobsdb.com/th/job/90346685?type=sta...  ...            0   \n",
       "19  https://th.jobsdb.com/th/job/89901519?type=sta...  ...            0   \n",
       "\n",
       "   skill_kubernetes skill_mlflow  skill_fastapi  skill_flask  skill_streamlit  \\\n",
       "0                 0            0              0            0                0   \n",
       "1                 0            0              0            0                0   \n",
       "2                 0            0              0            0                0   \n",
       "3                 0            0              0            0                0   \n",
       "4                 0            0              0            0                0   \n",
       "5                 0            0              0            0                0   \n",
       "6                 0            0              0            0                0   \n",
       "7                 0            0              0            0                0   \n",
       "8                 0            0              0            0                0   \n",
       "9                 0            0              0            0                0   \n",
       "10                0            0              0            0                0   \n",
       "11                0            0              0            0                0   \n",
       "12                0            0              0            0                0   \n",
       "13                0            0              0            0                0   \n",
       "14                0            0              0            0                0   \n",
       "15                0            0              0            0                0   \n",
       "16                0            0              0            0                0   \n",
       "17                0            0              0            0                0   \n",
       "18                0            0              0            0                0   \n",
       "19                0            0              0            0                0   \n",
       "\n",
       "    skill_statistics  skill_git  skill_api  skill_linux  \n",
       "0                  1          0          0            0  \n",
       "1                  1          0          0            0  \n",
       "2                  0          0          0            0  \n",
       "3                  0          0          0            0  \n",
       "4                  0          0          0            0  \n",
       "5                  1          0          0            0  \n",
       "6                  1          0          0            0  \n",
       "7                  0          0          0            0  \n",
       "8                  1          0          0            0  \n",
       "9                  1          0          0            0  \n",
       "10                 1          0          0            0  \n",
       "11                 0          0          0            0  \n",
       "12                 0          0          0            0  \n",
       "13                 1          0          0            0  \n",
       "14                 1          0          0            0  \n",
       "15                 1          0          0            0  \n",
       "16                 0          0          0            0  \n",
       "17                 1          0          0            0  \n",
       "18                 0          0          0            0  \n",
       "19                 1          0          0            0  \n",
       "\n",
       "[20 rows x 63 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from urllib.parse import parse_qs, urlencode, urljoin, urlparse, urlunparse\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# ---- Search settings ----\n",
    "keyword = \"data analyst\"\n",
    "location = \"\"  # optional: e.g. \"bangkok\"\n",
    "\n",
    "MAX_PAGES = 10\n",
    "SLEEP_SECONDS = 1.0\n",
    "DETAIL_SLEEP_SECONDS = 0.5\n",
    "\n",
    "keyword_slug = \"-\".join(keyword.lower().split())\n",
    "base_url = f\"https://th.jobsdb.com/th/{keyword_slug}-jobs\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/121.0.0.0 Safari/537.36\"\n",
    "    ),\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9,th;q=0.8\",\n",
    "}\n",
    "\n",
    "SKILLS = {\n",
    "    # ---------------- Core Programming ----------------\n",
    "    \"python\": [\"python\"],\n",
    "    \"r\": [\" r \", \" r,\", \" r\\n\", \" r/\"],\n",
    "    \"java\": [\"java\"],\n",
    "    \"scala\": [\"scala\"],\n",
    "    \"c++\": [\"c++\"],\n",
    "\n",
    "    # ---------------- SQL & Databases ----------------\n",
    "    \"sql\": [\" sql \", \"mysql\", \"postgres\", \"postgresql\", \"oracle\", \"sql server\", \"mssql\", \"sqlite\"],\n",
    "    \"mongodb\": [\"mongodb\", \"mongo\"],\n",
    "    \"redis\": [\"redis\"],\n",
    "    \"cassandra\": [\"cassandra\"],\n",
    "    \"elasticsearch\": [\"elasticsearch\", \"elastic search\"],\n",
    "\n",
    "    # ---------------- Data Libraries ----------------\n",
    "    \"pandas\": [\"pandas\"],\n",
    "    \"numpy\": [\"numpy\"],\n",
    "    \"scipy\": [\"scipy\"],\n",
    "    \"sklearn\": [\"scikit-learn\", \"sklearn\"],\n",
    "\n",
    "    # ---------------- Machine Learning ----------------\n",
    "    \"machine_learning\": [\n",
    "        \"machine learning\", \"supervised\", \"unsupervised\",\n",
    "        \"random forest\", \"xgboost\", \"lightgbm\", \"catboost\"\n",
    "    ],\n",
    "\n",
    "    # ---------------- Deep Learning ----------------\n",
    "    \"deep_learning\": [\n",
    "        \"deep learning\", \"neural network\", \"cnn\", \"rnn\", \"lstm\", \"transformer\"\n",
    "    ],\n",
    "\n",
    "    # ---------------- GenAI / LLM ----------------\n",
    "    \"llm\": [\"llm\", \"large language model\"],\n",
    "    \"rag\": [\"rag\", \"retrieval augmented generation\"],\n",
    "    \"langchain\": [\"langchain\"],\n",
    "    \"openai\": [\"openai\"],\n",
    "    \"huggingface\": [\"huggingface\"],\n",
    "    \"prompt_engineering\": [\"prompt engineering\"],\n",
    "    \"vector_db\": [\"vector database\", \"pinecone\", \"faiss\", \"weaviate\", \"milvus\"],\n",
    "\n",
    "    # ---------------- Visualization / BI ----------------\n",
    "    \"excel\": [\"excel\", \"vlookup\", \"pivot table\", \"power query\"],\n",
    "    \"powerbi\": [\"power bi\", \"powerbi\", \"dax\"],\n",
    "    \"tableau\": [\"tableau\"],\n",
    "    \"matplotlib\": [\"matplotlib\"],\n",
    "    \"seaborn\": [\"seaborn\"],\n",
    "    \"plotly\": [\"plotly\"],\n",
    "\n",
    "    # ---------------- Big Data ----------------\n",
    "    \"spark\": [\"spark\", \"pyspark\"],\n",
    "    \"hadoop\": [\"hadoop\"],\n",
    "    \"kafka\": [\"kafka\"],\n",
    "\n",
    "    # ---------------- Cloud ----------------\n",
    "    \"aws\": [\"aws\", \"amazon web services\", \"s3\", \"redshift\", \"athena\", \"glue\", \"lambda\"],\n",
    "    \"gcp\": [\"gcp\", \"google cloud\", \"bigquery\", \"cloud storage\"],\n",
    "    \"azure\": [\"azure\", \"synapse\", \"databricks\"],\n",
    "\n",
    "    # ---------------- Data Engineering ----------------\n",
    "    \"etl\": [\"etl\", \"elt\", \"data pipeline\"],\n",
    "    \"airflow\": [\"airflow\"],\n",
    "    \"dbt\": [\"dbt\"],\n",
    "    \"snowflake\": [\"snowflake\"],\n",
    "\n",
    "    # ---------------- MLOps / Deployment ----------------\n",
    "    \"docker\": [\"docker\"],\n",
    "    \"kubernetes\": [\"kubernetes\", \"k8s\"],\n",
    "    \"mlflow\": [\"mlflow\"],\n",
    "    \"fastapi\": [\"fastapi\"],\n",
    "    \"flask\": [\"flask\"],\n",
    "    \"streamlit\": [\"streamlit\"],\n",
    "\n",
    "    # ---------------- Statistics ----------------\n",
    "    \"statistics\": [\n",
    "        \"statistics\", \"statistical\", \"hypothesis testing\",\n",
    "        \"regression\", \"anova\", \"probability\"\n",
    "    ],\n",
    "\n",
    "    # ---------------- Version Control ----------------\n",
    "    \"git\": [\"git\", \"github\", \"gitlab\"],\n",
    "\n",
    "    # ---------------- APIs ----------------\n",
    "    \"api\": [\"api\", \"rest api\"],\n",
    "\n",
    "    # ---------------- Linux ----------------\n",
    "    \"linux\": [\"linux\", \"unix\"],    \n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "THAI_PROVINCES = [\n",
    "    \"กรุงเทพมหานคร\", \"กระบี่\", \"กาญจนบุรี\", \"กาฬสินธุ์\", \"กำแพงเพชร\", \"ขอนแก่น\", \"จันทบุรี\", \"ฉะเชิงเทรา\", \"ชลบุรี\", \"ชัยนาท\",\n",
    "    \"ชัยภูมิ\", \"ชุมพร\", \"เชียงราย\", \"เชียงใหม่\", \"ตรัง\", \"ตราด\", \"ตาก\", \"นครนายก\", \"นครปฐม\", \"นครพนม\", \"นครราชสีมา\",\n",
    "    \"นครศรีธรรมราช\", \"นครสวรรค์\", \"นนทบุรี\", \"นราธิวาส\", \"น่าน\", \"บึงกาฬ\", \"บุรีรัมย์\", \"ปทุมธานี\", \"ประจวบคีรีขันธ์\",\n",
    "    \"ปราจีนบุรี\", \"ปัตตานี\", \"พระนครศรีอยุธยา\", \"พังงา\", \"พัทลุง\", \"พิจิตร\", \"พิษณุโลก\", \"เพชรบุรี\", \"เพชรบูรณ์\", \"แพร่\",\n",
    "    \"พะเยา\", \"ภูเก็ต\", \"มหาสารคาม\", \"มุกดาหาร\", \"แม่ฮ่องสอน\", \"ยะลา\", \"ยโสธร\", \"ร้อยเอ็ด\", \"ระนอง\", \"ระยอง\", \"ราชบุรี\",\n",
    "    \"ลพบุรี\", \"ลำปาง\", \"ลำพูน\", \"เลย\", \"ศรีสะเกษ\", \"สกลนคร\", \"สงขลา\", \"สตูล\", \"สมุทรปราการ\", \"สมุทรสงคราม\", \"สมุทรสาคร\",\n",
    "    \"สระแก้ว\", \"สระบุรี\", \"สิงห์บุรี\", \"สุโขทัย\", \"สุพรรณบุรี\", \"สุราษฎร์ธานี\", \"สุรินทร์\", \"หนองคาย\", \"หนองบัวลำภู\", \"อ่างทอง\",\n",
    "    \"อุดรธานี\", \"อุตรดิตถ์\", \"อุทัยธานี\", \"อุบลราชธานี\", \"อำนาจเจริญ\",\n",
    "]\n",
    "\n",
    "EN_TO_THAI_PROVINCE = {\n",
    "    \"bangkok\": \"กรุงเทพมหานคร\",\n",
    "    \"nonthaburi\": \"นนทบุรี\",\n",
    "    \"pathum thani\": \"ปทุมธานี\",\n",
    "    \"samut prakan\": \"สมุทรปราการ\",\n",
    "    \"chon buri\": \"ชลบุรี\",\n",
    "    \"chonburi\": \"ชลบุรี\",\n",
    "    \"rayong\": \"ระยอง\",\n",
    "    \"chiang mai\": \"เชียงใหม่\",\n",
    "    \"chiang rai\": \"เชียงราย\",\n",
    "    \"phuket\": \"ภูเก็ต\",\n",
    "    \"khon kaen\": \"ขอนแก่น\",\n",
    "    \"nakhon ratchasima\": \"นครราชสีมา\",\n",
    "    \"korat\": \"นครราชสีมา\",\n",
    "    \"songkhla\": \"สงขลา\",\n",
    "    \"surat thani\": \"สุราษฎร์ธานี\",\n",
    "    \"udon thani\": \"อุดรธานี\",\n",
    "    \"ubon ratchathani\": \"อุบลราชธานี\",\n",
    "    \"nakhon pathom\": \"นครปฐม\",\n",
    "    \"phra nakhon si ayutthaya\": \"พระนครศรีอยุธยา\",\n",
    "    \"ayutthaya\": \"พระนครศรีอยุธยา\",\n",
    "}\n",
    "\n",
    "\n",
    "def update_query_in_url(url: str, **params) -> str:\n",
    "    parsed = urlparse(url)\n",
    "    query = parse_qs(parsed.query)\n",
    "    for key, value in params.items():\n",
    "        query[key] = [str(value)]\n",
    "    new_query = urlencode(query, doseq=True)\n",
    "    return urlunparse((parsed.scheme, parsed.netloc, parsed.path, parsed.params, new_query, parsed.fragment))\n",
    "\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", (text or \"\")).strip()\n",
    "\n",
    "\n",
    "def normalize_for_match(text: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\", \" \", (text or \"\").lower()).strip()\n",
    "\n",
    "\n",
    "def keyword_match_groups_from_query(search_keyword: str) -> list[list[str]]:\n",
    "    term_variants = {\n",
    "        \"data\": [\"data\"],\n",
    "        \"scientist\": [\"scientist\", \"science\", \"scien\", \"scient\"],\n",
    "        \"science\": [\"science\", \"scientist\", \"scien\", \"scient\"],\n",
    "        \"engineer\": [\"engineer\", \"engineering\", \"eng\"],\n",
    "        \"analyst\": [\"analyst\", \"analytics\", \"analysis\"],\n",
    "        \"developer\": [\"developer\", \"development\", \"dev\"],\n",
    "    }\n",
    "\n",
    "    tokens = [token for token in normalize_for_match(search_keyword).split() if token]\n",
    "    groups = []\n",
    "\n",
    "    for token in tokens:\n",
    "        groups.append(term_variants.get(token, [token]))\n",
    "\n",
    "    return groups\n",
    "\n",
    "\n",
    "def title_matches_keyword(title: str, keyword_groups: list[list[str]]) -> bool:\n",
    "    if not keyword_groups:\n",
    "        return True\n",
    "    title_norm = normalize_for_match(title)\n",
    "    return all(any(variant in title_norm for variant in group) for group in keyword_groups)\n",
    "\n",
    "\n",
    "def extract_salary(text: str) -> str:\n",
    "    patterns = [\n",
    "        r\"THB\\s*[\\d,]+\\s*[-–]\\s*THB\\s*[\\d,]+\",\n",
    "        r\"THB\\s*[\\d,]+\",\n",
    "        r\"[\\d,]+\\s*[-–]\\s*[\\d,]+\\s*บาท\",\n",
    "        r\"[\\d,]+\\s*บาท\",\n",
    "        r\"Negotiable|ไม่ระบุเงินเดือน|ตามตกลง|ตามประสบการณ์\",\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text, flags=re.IGNORECASE)\n",
    "        if match:\n",
    "            return clean_text(match.group(0))\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def is_probable_salary(text: str) -> bool:\n",
    "    if not text:\n",
    "        return False\n",
    "    text_norm = text.lower()\n",
    "    salary_keywords = [\"thb\", \"บาท\", \"salary\", \"negotiable\", \"ตามตกลง\", \"ตามประสบการณ์\"]\n",
    "    if any(key in text_norm for key in salary_keywords):\n",
    "        return True\n",
    "    return bool(re.search(r\"\\d\", text_norm) and re.search(r\"[-–]\", text_norm))\n",
    "\n",
    "\n",
    "def guess_province_name(location_text: str) -> str:\n",
    "    location_clean = clean_text(location_text)\n",
    "    if not location_clean:\n",
    "        return \"\"\n",
    "\n",
    "    for province in THAI_PROVINCES:\n",
    "        if province in location_clean:\n",
    "            return province\n",
    "\n",
    "    location_lower = location_clean.lower()\n",
    "    for english_name, thai_name in EN_TO_THAI_PROVINCE.items():\n",
    "        if re.search(rf\"\\b{re.escape(english_name)}\\b\", location_lower):\n",
    "            return thai_name\n",
    "\n",
    "    parts = [clean_text(part) for part in re.split(r\",|\\||/\", location_clean) if clean_text(part)]\n",
    "    if not parts:\n",
    "        return \"\"\n",
    "\n",
    "    tail = parts[-1]\n",
    "    tail = re.sub(r\"^(เขต|อ\\.|อำเภอ|จ\\.|จังหวัด)\\s*\", \"\", tail).strip()\n",
    "    return tail\n",
    "\n",
    "\n",
    "def extract_job_detail_text(job_url: str) -> str:\n",
    "    try:\n",
    "        response = requests.get(job_url, headers=headers, timeout=30)\n",
    "        response.raise_for_status()\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    detail_el = soup.select_one(\"[data-automation='jobAdDetails']\")\n",
    "    if detail_el:\n",
    "        return clean_text(detail_el.get_text(\"\\n\", strip=True))\n",
    "\n",
    "    section_el = soup.select_one(\"section\")\n",
    "    if section_el:\n",
    "        return clean_text(section_el.get_text(\"\\n\", strip=True))\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def variant_matches_text(variant: str, normalized_text: str) -> bool:\n",
    "    variant_norm = normalize_for_match(variant)\n",
    "    if not variant_norm:\n",
    "        return False\n",
    "\n",
    "    pattern = re.escape(variant_norm)\n",
    "    pattern = pattern.replace(r\"\\ \", r\"\\s+\")\n",
    "    regex = rf\"(?<![a-z0-9]){pattern}(?![a-z0-9])\"\n",
    "    return re.search(regex, normalized_text) is not None\n",
    "\n",
    "\n",
    "def extract_skills(detail_text: str) -> dict:\n",
    "    text_norm = normalize_for_match(detail_text)\n",
    "    found = []\n",
    "    flags = {}\n",
    "\n",
    "    for skill_key, variants in SKILLS.items():\n",
    "        matched = any(variant_matches_text(variant, text_norm) for variant in variants)\n",
    "        flags[f\"skill_{skill_key}\"] = int(matched)\n",
    "        if matched:\n",
    "            found.append(skill_key)\n",
    "\n",
    "    flags[\"matched_skills\"] = \"|\".join(found)\n",
    "    flags[\"matched_skill_count\"] = len(found)\n",
    "    return flags\n",
    "\n",
    "\n",
    "def parse_card(card, page_num: int, search_keyword: str) -> dict:\n",
    "    title_el = card.select_one(\"a[data-automation='jobTitle']\")\n",
    "    company_el = card.select_one(\"a[data-automation='jobCompany'], [data-automation='jobCompany']\")\n",
    "    location_el = card.select_one(\"a[data-automation='jobLocation'], [data-automation='jobCardLocation']\")\n",
    "    date_el = card.select_one(\"[data-automation='jobListingDate']\")\n",
    "    salary_el = card.select_one(\"[data-automation='jobSalary']\")\n",
    "    overlay_link_el = card.select_one(\"a[data-automation='job-list-item-link-overlay'][href]\")\n",
    "\n",
    "    title = clean_text(title_el.get_text(\" \", strip=True) if title_el else \"\")\n",
    "    company = clean_text(company_el.get_text(\" \", strip=True) if company_el else \"\")\n",
    "    location_name = clean_text(location_el.get_text(\" \", strip=True) if location_el else \"\")\n",
    "    posted_date = clean_text(date_el.get_text(\" \", strip=True) if date_el else \"\")\n",
    "\n",
    "    salary_candidate = clean_text(salary_el.get_text(\" \", strip=True) if salary_el else \"\")\n",
    "    salary = salary_candidate if is_probable_salary(salary_candidate) else \"\"\n",
    "\n",
    "    href = \"\"\n",
    "    if overlay_link_el:\n",
    "        href = overlay_link_el.get(\"href\", \"\")\n",
    "    elif title_el and title_el.get(\"href\"):\n",
    "        href = title_el.get(\"href\", \"\")\n",
    "    job_url = urljoin(\"https://th.jobsdb.com\", href) if href else \"\"\n",
    "\n",
    "    raw_text = clean_text(card.get_text(\"\\n\", strip=True))\n",
    "    if not salary:\n",
    "        salary = extract_salary(raw_text)\n",
    "\n",
    "    province_name = guess_province_name(location_name)\n",
    "\n",
    "    return {\n",
    "        \"keyword\": search_keyword,\n",
    "        \"province_code\": \"\",\n",
    "        \"province_name\": province_name,\n",
    "        \"page\": page_num,\n",
    "        \"job_title\": title,\n",
    "        \"company\": company,\n",
    "        \"location\": location_name,\n",
    "        \"salary\": salary,\n",
    "        \"posted_date\": posted_date,\n",
    "        \"job_url\": job_url,\n",
    "        \"raw_text\": raw_text,\n",
    "    }\n",
    "\n",
    "\n",
    "def scrape_jobsdb(search_url: str, search_location: str, max_pages: int = 10, sleep_seconds: float = 1.0) -> pd.DataFrame:\n",
    "    keyword_groups = keyword_match_groups_from_query(keyword)\n",
    "\n",
    "    all_rows = []\n",
    "    seen_urls = set()\n",
    "\n",
    "    print(f\"[Search] Starting JobsDB crawl: max_pages={max_pages}\")\n",
    "\n",
    "    for page_num in range(1, max_pages + 1):\n",
    "        page_url = update_query_in_url(search_url, page=page_num)\n",
    "        if search_location.strip():\n",
    "            page_url = update_query_in_url(page_url, where=search_location.strip())\n",
    "\n",
    "        print(f\"[Search] Page {page_num}/{max_pages} -> request\")\n",
    "        response = requests.get(page_url, headers=headers, timeout=30)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        cards = soup.select(\"article[data-testid='job-card'], article[data-automation='normalJob']\")\n",
    "        print(f\"[Search] Page {page_num}/{max_pages} -> found cards: {len(cards)}\")\n",
    "\n",
    "        if not cards:\n",
    "            print(f\"[Search] Page {page_num}/{max_pages} -> no cards, stopping\")\n",
    "            break\n",
    "\n",
    "        page_rows = []\n",
    "        for card in cards:\n",
    "            row = parse_card(card, page_num=page_num, search_keyword=keyword)\n",
    "            if not row[\"job_title\"] or not row[\"job_url\"]:\n",
    "                continue\n",
    "            if not title_matches_keyword(row[\"job_title\"], keyword_groups):\n",
    "                continue\n",
    "            if row[\"job_url\"] in seen_urls:\n",
    "                continue\n",
    "\n",
    "            seen_urls.add(row[\"job_url\"])\n",
    "            page_rows.append(row)\n",
    "\n",
    "        if not page_rows:\n",
    "            print(f\"[Search] Page {page_num}/{max_pages} -> no keyword matches, stopping\")\n",
    "            break\n",
    "\n",
    "        all_rows.extend(page_rows)\n",
    "        print(f\"[Search] Page {page_num}/{max_pages} -> kept {len(page_rows)} | cumulative={len(all_rows)}\")\n",
    "\n",
    "        if sleep_seconds > 0:\n",
    "            time.sleep(sleep_seconds)\n",
    "\n",
    "    print(f\"[Detail] Start detail scrape for {len(all_rows)} jobs\")\n",
    "\n",
    "    for idx, row in enumerate(all_rows, start=1):\n",
    "        detail_text = extract_job_detail_text(row[\"job_url\"])\n",
    "        row[\"job_detail_text\"] = detail_text\n",
    "\n",
    "        skill_result = extract_skills(detail_text)\n",
    "        row.update(skill_result)\n",
    "\n",
    "        if len(all_rows) <= 50 or idx % 10 == 0 or idx == len(all_rows):\n",
    "            percent = (idx / len(all_rows)) * 100 if all_rows else 100\n",
    "            print(f\"[Detail] {idx}/{len(all_rows)} ({percent:.1f}%)\")\n",
    "\n",
    "        if DETAIL_SLEEP_SECONDS > 0:\n",
    "            time.sleep(DETAIL_SLEEP_SECONDS)\n",
    "\n",
    "    df = pd.DataFrame(all_rows)\n",
    "\n",
    "    if not df.empty:\n",
    "        ordered_cols = [\n",
    "            \"keyword\",\n",
    "            \"province_code\",\n",
    "            \"province_name\",\n",
    "            \"page\",\n",
    "            \"job_title\",\n",
    "            \"company\",\n",
    "            \"location\",\n",
    "            \"salary\",\n",
    "            \"posted_date\",\n",
    "            \"job_url\",\n",
    "            \"raw_text\",\n",
    "            \"job_detail_text\",\n",
    "            \"matched_skills\",\n",
    "            \"matched_skill_count\",\n",
    "        ] + [f\"skill_{k}\" for k in SKILLS.keys()]\n",
    "\n",
    "        for col in ordered_cols:\n",
    "            if col not in df.columns:\n",
    "                df[col] = \"\" if not col.startswith(\"skill_\") and col != \"matched_skill_count\" else 0\n",
    "\n",
    "        df = df[ordered_cols].drop_duplicates(subset=[\"job_url\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "jobs_df = scrape_jobsdb(\n",
    "    base_url,\n",
    "    search_location=location,\n",
    "    max_pages=MAX_PAGES,\n",
    "    sleep_seconds=SLEEP_SECONDS,\n",
    ")\n",
    "print(f\"\\nTotal unique jobs: {len(jobs_df)}\")\n",
    "\n",
    "output_file = f\"jobsdb_{keyword_slug}_{datetime.now().strftime('%Y%m%d')}.csv\"\n",
    "output_path = Path(output_file)\n",
    "jobs_df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"Saved to: {output_path.resolve()}\")\n",
    "\n",
    "jobs_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf694422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hello world"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
