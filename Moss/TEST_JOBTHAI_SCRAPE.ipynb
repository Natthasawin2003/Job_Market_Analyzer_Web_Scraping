{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c788434d",
   "metadata": {},
   "source": [
    "# JobThai Web Scraper (Data Scientist)\n",
    "\n",
    "This notebook scrapes JobThai search results for **Data Scientist**, extracts structured fields, and saves them to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d932af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Search] Starting page crawl: max_pages=10\n",
      "[Search] Page 1/10 -> request\n",
      "[Search] Page 1/10 -> found cards: 20\n",
      "[Search] Page 1/10 -> kept 20 | cumulative=20\n",
      "[Search] Page 2/10 -> request\n",
      "[Search] Page 2/10 -> found cards: 20\n",
      "[Search] Page 2/10 -> kept 20 | cumulative=40\n",
      "[Search] Page 3/10 -> request\n",
      "[Search] Page 3/10 -> found cards: 20\n",
      "[Search] Page 3/10 -> kept 20 | cumulative=60\n",
      "[Search] Page 4/10 -> request\n",
      "[Search] Page 4/10 -> found cards: 20\n",
      "[Search] Page 4/10 -> kept 1 | cumulative=61\n",
      "[Search] Page 5/10 -> request\n",
      "[Search] Page 5/10 -> found cards: 20\n",
      "[Search] Page 5/10 -> no keyword matches, stopping\n",
      "[Detail] Starting province lookup for 61 jobs\n",
      "[Detail] 10/61 (16.4%)\n",
      "[Detail] 20/61 (32.8%)\n",
      "[Detail] 30/61 (49.2%)\n",
      "[Detail] 40/61 (65.6%)\n",
      "[Detail] 50/61 (82.0%)\n",
      "[Detail] 60/61 (98.4%)\n",
      "[Detail] 61/61 (100.0%)\n",
      "[Done] Completed in 189.8s\n",
      "\n",
      "Total unique jobs: 61\n",
      "Saved CSV: G:\\Users\\Moss\\Documents\\PYTHON_PROJECT\\Job_Market_Analyzer_Web_Scraping\\Moss\\jobthai_data-analyst_20260217.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>province_code</th>\n",
       "      <th>province_name</th>\n",
       "      <th>page</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>job_url</th>\n",
       "      <th>raw_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>01</td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>บริษัท เมืองไทย แคปปิตอล จำกัด (มหาชน)</td>\n",
       "      <td>MRT บางพลัด</td>\n",
       "      <td>22,000 - 23,000 บาท</td>\n",
       "      <td>17 ก.พ. 69</td>\n",
       "      <td>https://www.jobthai.com/th/company/job/1752582</td>\n",
       "      <td>Data Analyst บริษัท เมืองไทย แคปปิตอล จำกัด (ม...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>01</td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>S45 Clinic</td>\n",
       "      <td>BTS พร้อมพงษ์</td>\n",
       "      <td>ตามตกลง</td>\n",
       "      <td>16 ก.พ. 69</td>\n",
       "      <td>https://www.jobthai.com/th/company/job/1844306</td>\n",
       "      <td>Data Analyst S45 Clinic S45 Clinic BTS พร้อมพง...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>32</td>\n",
       "      <td>จ.พระนครศรีอยุธยา</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Tech Solution AI Co., Ltd.</td>\n",
       "      <td>อ.วังน้อย จ.พระนครศรีอยุธยา</td>\n",
       "      <td>ตามตกลง</td>\n",
       "      <td>17 ก.พ. 69</td>\n",
       "      <td>https://www.jobthai.com/th/company/job/1857706</td>\n",
       "      <td>Data Analyst Tech Solution AI Co., Ltd. Tech S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>01</td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>บริษัท เอฟซีซี เซอร์วิสเซส จำกัด</td>\n",
       "      <td>MRT ภาวนา</td>\n",
       "      <td>17,000 - 22,000 บาท</td>\n",
       "      <td>17 ก.พ. 69</td>\n",
       "      <td>https://www.jobthai.com/th/company/job/1755307</td>\n",
       "      <td>Data Analyst บริษัท เอฟซีซี เซอร์วิสเซส จำกัด ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>01</td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>บริษัท เริ่มใหม่ จำกัด</td>\n",
       "      <td>เขตสายไหม กรุงเทพมหานคร</td>\n",
       "      <td>ตามความสามารถและประสบการณ์</td>\n",
       "      <td>17 ก.พ. 69</td>\n",
       "      <td>https://www.jobthai.com/th/company/job/1643374</td>\n",
       "      <td>Data Analyst บริษัท เริ่มใหม่ จำกัด บริษัท เริ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>01</td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>บริษัท ซาบีน่า จำกัด (มหาชน)</td>\n",
       "      <td>เขตบางกอกน้อย กรุงเทพมหานคร</td>\n",
       "      <td>ตามตกลง</td>\n",
       "      <td>17 ก.พ. 69</td>\n",
       "      <td>https://www.jobthai.com/th/company/job/1862880</td>\n",
       "      <td>Data Analyst บริษัท ซาบีน่า จำกัด (มหาชน) บริษ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>01</td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>บริษัท ชับบ์สามัคคีประกันภัย จำกัด (มหาชน)</td>\n",
       "      <td>เขตหลักสี่ กรุงเทพมหานคร</td>\n",
       "      <td>ตามตกลง</td>\n",
       "      <td>17 ก.พ. 69</td>\n",
       "      <td>https://www.jobthai.com/th/company/job/1824648</td>\n",
       "      <td>Data Analyst บริษัท ชับบ์สามัคคีประกันภัย จำกั...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>28</td>\n",
       "      <td>จ.ปทุมธานี</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>บริษัท ดูโฮม จำกัด (มหาชน)</td>\n",
       "      <td>อ.เมืองปทุมธานี จ.ปทุมธานี</td>\n",
       "      <td>18,000 - 30,000 บาท</td>\n",
       "      <td>17 ก.พ. 69</td>\n",
       "      <td>https://www.jobthai.com/th/company/job/1809674</td>\n",
       "      <td>Data Analyst บริษัท ดูโฮม จำกัด (มหาชน) บริษัท...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>01</td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst / Business Data Analyst</td>\n",
       "      <td>บริษัท ฟังก์ชั่น อินเตอร์เนชั่นแนล จำกัด (มหาชน)</td>\n",
       "      <td>เขตคลองสามวา กรุงเทพมหานคร</td>\n",
       "      <td>20,000 - 30,000 บาท</td>\n",
       "      <td>17 ก.พ. 69</td>\n",
       "      <td>https://www.jobthai.com/th/company/job/1854175</td>\n",
       "      <td>Data Analyst / Business Data Analyst 17 ก.พ. 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>01</td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst - BNG</td>\n",
       "      <td>บริษัท เบญจจินดา โฮลดิ้ง จำกัด</td>\n",
       "      <td>SRT บางเขน</td>\n",
       "      <td>ตามประสบการณ์</td>\n",
       "      <td>16 ก.พ. 69</td>\n",
       "      <td>https://www.jobthai.com/th/company/job/1858004</td>\n",
       "      <td>Data Analyst - BNG บริษัท เบญจจินดา โฮลดิ้ง จำ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        keyword province_code      province_name  page  \\\n",
       "0  Data Analyst            01      กรุงเทพมหานคร     1   \n",
       "1  Data Analyst            01      กรุงเทพมหานคร     1   \n",
       "2  Data Analyst            32  จ.พระนครศรีอยุธยา     1   \n",
       "3  Data Analyst            01      กรุงเทพมหานคร     1   \n",
       "4  Data Analyst            01      กรุงเทพมหานคร     1   \n",
       "5  Data Analyst            01      กรุงเทพมหานคร     1   \n",
       "6  Data Analyst            01      กรุงเทพมหานคร     1   \n",
       "7  Data Analyst            28         จ.ปทุมธานี     1   \n",
       "8  Data Analyst            01      กรุงเทพมหานคร     1   \n",
       "9  Data Analyst            01      กรุงเทพมหานคร     1   \n",
       "\n",
       "                              job_title  \\\n",
       "0                          Data Analyst   \n",
       "1                          Data Analyst   \n",
       "2                          Data Analyst   \n",
       "3                          Data Analyst   \n",
       "4                          Data Analyst   \n",
       "5                          Data Analyst   \n",
       "6                          Data Analyst   \n",
       "7                          Data Analyst   \n",
       "8  Data Analyst / Business Data Analyst   \n",
       "9                    Data Analyst - BNG   \n",
       "\n",
       "                                            company  \\\n",
       "0            บริษัท เมืองไทย แคปปิตอล จำกัด (มหาชน)   \n",
       "1                                        S45 Clinic   \n",
       "2                        Tech Solution AI Co., Ltd.   \n",
       "3                  บริษัท เอฟซีซี เซอร์วิสเซส จำกัด   \n",
       "4                            บริษัท เริ่มใหม่ จำกัด   \n",
       "5                      บริษัท ซาบีน่า จำกัด (มหาชน)   \n",
       "6        บริษัท ชับบ์สามัคคีประกันภัย จำกัด (มหาชน)   \n",
       "7                        บริษัท ดูโฮม จำกัด (มหาชน)   \n",
       "8  บริษัท ฟังก์ชั่น อินเตอร์เนชั่นแนล จำกัด (มหาชน)   \n",
       "9                    บริษัท เบญจจินดา โฮลดิ้ง จำกัด   \n",
       "\n",
       "                      location                      salary posted_date  \\\n",
       "0                  MRT บางพลัด         22,000 - 23,000 บาท  17 ก.พ. 69   \n",
       "1                BTS พร้อมพงษ์                     ตามตกลง  16 ก.พ. 69   \n",
       "2  อ.วังน้อย จ.พระนครศรีอยุธยา                     ตามตกลง  17 ก.พ. 69   \n",
       "3                    MRT ภาวนา         17,000 - 22,000 บาท  17 ก.พ. 69   \n",
       "4      เขตสายไหม กรุงเทพมหานคร  ตามความสามารถและประสบการณ์  17 ก.พ. 69   \n",
       "5  เขตบางกอกน้อย กรุงเทพมหานคร                     ตามตกลง  17 ก.พ. 69   \n",
       "6     เขตหลักสี่ กรุงเทพมหานคร                     ตามตกลง  17 ก.พ. 69   \n",
       "7   อ.เมืองปทุมธานี จ.ปทุมธานี         18,000 - 30,000 บาท  17 ก.พ. 69   \n",
       "8   เขตคลองสามวา กรุงเทพมหานคร         20,000 - 30,000 บาท  17 ก.พ. 69   \n",
       "9                   SRT บางเขน               ตามประสบการณ์  16 ก.พ. 69   \n",
       "\n",
       "                                          job_url  \\\n",
       "0  https://www.jobthai.com/th/company/job/1752582   \n",
       "1  https://www.jobthai.com/th/company/job/1844306   \n",
       "2  https://www.jobthai.com/th/company/job/1857706   \n",
       "3  https://www.jobthai.com/th/company/job/1755307   \n",
       "4  https://www.jobthai.com/th/company/job/1643374   \n",
       "5  https://www.jobthai.com/th/company/job/1862880   \n",
       "6  https://www.jobthai.com/th/company/job/1824648   \n",
       "7  https://www.jobthai.com/th/company/job/1809674   \n",
       "8  https://www.jobthai.com/th/company/job/1854175   \n",
       "9  https://www.jobthai.com/th/company/job/1858004   \n",
       "\n",
       "                                            raw_text  \n",
       "0  Data Analyst บริษัท เมืองไทย แคปปิตอล จำกัด (ม...  \n",
       "1  Data Analyst S45 Clinic S45 Clinic BTS พร้อมพง...  \n",
       "2  Data Analyst Tech Solution AI Co., Ltd. Tech S...  \n",
       "3  Data Analyst บริษัท เอฟซีซี เซอร์วิสเซส จำกัด ...  \n",
       "4  Data Analyst บริษัท เริ่มใหม่ จำกัด บริษัท เริ...  \n",
       "5  Data Analyst บริษัท ซาบีน่า จำกัด (มหาชน) บริษ...  \n",
       "6  Data Analyst บริษัท ชับบ์สามัคคีประกันภัย จำกั...  \n",
       "7  Data Analyst บริษัท ดูโฮม จำกัด (มหาชน) บริษัท...  \n",
       "8  Data Analyst / Business Data Analyst 17 ก.พ. 6...  \n",
       "9  Data Analyst - BNG บริษัท เบญจจินดา โฮลดิ้ง จำ...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "from pathlib import Path\n",
    "from urllib.parse import parse_qs, urlencode, urlparse, urlunparse\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "SEARCH_URL = \"https://www.jobthai.com/th/jobs?keyword=Data%20Analyst&page=1&orderBy=RELEVANCE_SEARCH\"\n",
    "OUTPUT_CSV = \"jobthai_data-analyst_20260217.csv\"\n",
    "MAX_PAGES = 10\n",
    "SLEEP_SECONDS = 1.0\n",
    "DETAIL_SLEEP_SECONDS = 0.5\n",
    "\n",
    "\n",
    "def normalize_province_code(value) -> str:\n",
    "    text = str(value).strip()\n",
    "    if text.isdigit():\n",
    "        number = int(text)\n",
    "        if number <= 0:\n",
    "            raise ValueError(f\"Province must be positive, got: {value}\")\n",
    "        return f\"{number:02d}\"\n",
    "    raise ValueError(f\"Invalid province code: {value}\")\n",
    "\n",
    "\n",
    "def normalize_for_match(text: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\", \" \", text.lower()).strip()\n",
    "\n",
    "\n",
    "def keyword_match_groups_from_query(keyword: str) -> list[list[str]]:\n",
    "    term_variants = {\n",
    "        \"data\": [\"data\"],\n",
    "        \"scientist\": [\"scientist\", \"science\", \"scien\", \"scient\"],\n",
    "        \"science\": [\"science\", \"scientist\", \"scien\", \"scient\"],\n",
    "        \"engineer\": [\"engineer\", \"engineering\", \"eng\"],\n",
    "        \"analyst\": [\"analyst\", \"analytics\", \"analysis\"],\n",
    "        \"developer\": [\"developer\", \"development\", \"dev\"],\n",
    "    }\n",
    "\n",
    "    tokens = [token for token in normalize_for_match(keyword).split() if token]\n",
    "    groups = []\n",
    "\n",
    "    for token in tokens:\n",
    "        if token in term_variants:\n",
    "            groups.append(term_variants[token])\n",
    "        else:\n",
    "            groups.append([token])\n",
    "\n",
    "    return groups\n",
    "\n",
    "\n",
    "def title_matches_keyword(title: str, keyword_groups: list[list[str]]) -> bool:\n",
    "    if not keyword_groups:\n",
    "        return True\n",
    "\n",
    "    title_norm = normalize_for_match(title)\n",
    "    return all(any(variant in title_norm for variant in group) for group in keyword_groups)\n",
    "\n",
    "\n",
    "def update_query_in_url(url: str, **params) -> str:\n",
    "    parsed = urlparse(url)\n",
    "    query = parse_qs(parsed.query)\n",
    "\n",
    "    for key, value in params.items():\n",
    "        query[key] = [str(value)]\n",
    "\n",
    "    new_query = urlencode(query, doseq=True)\n",
    "    return urlunparse((parsed.scheme, parsed.netloc, parsed.path, parsed.params, new_query, parsed.fragment))\n",
    "\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "\n",
    "def extract_salary(text: str) -> str:\n",
    "    patterns = [\n",
    "        r\"\\d[\\d,\\s]*\\s*-\\s*\\d[\\d,\\s]*\\s*บาท\",\n",
    "        r\"\\d[\\d,\\s]*\\s*บาท\",\n",
    "        r\"ตามโครงสร้างบริษัทฯ\",\n",
    "        r\"ตามประสบการณ์\",\n",
    "        r\"ตามตกลง\",\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            return clean_text(match.group(0))\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def extract_posted_date(text: str) -> str:\n",
    "    match = re.search(r\"\\b\\d{1,2}\\s+[ก-๙A-Za-z\\.]+\\s+\\d{2}\\b\", text)\n",
    "    return clean_text(match.group(0)) if match else \"\"\n",
    "\n",
    "\n",
    "def pick_text(parent, selectors: list[str]) -> str:\n",
    "    for selector in selectors:\n",
    "        element = parent.select_one(selector)\n",
    "        if element:\n",
    "            text = clean_text(element.get_text(\" \", strip=True))\n",
    "            if text:\n",
    "                return text\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def guess_location(lines: list[str], title: str, company: str, salary: str) -> str:\n",
    "    priority_keywords = [\"เขต\", \"กรุงเทพ\", \"จังหวัด\", \"อำเภอ\", \"อ.\", \"ต.\"]\n",
    "    transit_keywords = [\"BTS\", \"MRT\", \"SRT\", \"BRT\", \"Airport Rail Link\"]\n",
    "\n",
    "    for line in lines:\n",
    "        if line in {title, company, salary}:\n",
    "            continue\n",
    "        if any(keyword in line for keyword in priority_keywords):\n",
    "            return line\n",
    "\n",
    "    for line in lines:\n",
    "        if line in {title, company, salary}:\n",
    "            continue\n",
    "        if any(keyword in line for keyword in transit_keywords):\n",
    "            return line\n",
    "\n",
    "    if salary and salary in lines:\n",
    "        salary_idx = lines.index(salary)\n",
    "        for idx in range(salary_idx - 1, -1, -1):\n",
    "            candidate = lines[idx]\n",
    "            if candidate not in {title, company}:\n",
    "                return candidate\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def parse_card_from_title(title_node, page_num: int, keyword: str) -> dict:\n",
    "    title = clean_text(title_node.get_text(\" \", strip=True))\n",
    "\n",
    "    anchor = title_node.find_parent(\"a\", href=True)\n",
    "    href = anchor.get(\"href\", \"\") if anchor else \"\"\n",
    "    job_url = href if href.startswith(\"http\") else f\"https://www.jobthai.com{href}\"\n",
    "\n",
    "    card = anchor if anchor is not None else title_node\n",
    "\n",
    "    company = pick_text(card, [\n",
    "        'span[id^=\"job-list-company-name-\"]',\n",
    "        'h2.ohgq7e-0.enAWkF',\n",
    "    ])\n",
    "\n",
    "    location = pick_text(card, [\n",
    "        \"h3#location-text\",\n",
    "        \"h3.location-text\",\n",
    "    ])\n",
    "\n",
    "    salary = pick_text(card, [\n",
    "        \"span.salary-text\",\n",
    "        \"div.msklqa-20\",\n",
    "        \"div.msklqa-17\",\n",
    "    ])\n",
    "\n",
    "    posted_date = pick_text(card, [\n",
    "        \"span.msklqa-9\",\n",
    "    ])\n",
    "\n",
    "    raw_lines = [clean_text(x) for x in card.get_text(\"\\n\", strip=True).splitlines() if clean_text(x)]\n",
    "    raw_text = clean_text(\" \".join(raw_lines))\n",
    "\n",
    "    if not salary:\n",
    "        salary = extract_salary(raw_text)\n",
    "    if not posted_date:\n",
    "        posted_date = extract_posted_date(raw_text)\n",
    "    if not location:\n",
    "        location = guess_location(raw_lines, title=title, company=company, salary=salary)\n",
    "\n",
    "    return {\n",
    "        \"keyword\": keyword,\n",
    "        \"page\": page_num,\n",
    "        \"job_title\": title,\n",
    "        \"company\": company,\n",
    "        \"location\": location,\n",
    "        \"salary\": salary,\n",
    "        \"posted_date\": posted_date,\n",
    "        \"job_url\": job_url,\n",
    "        \"raw_text\": raw_text,\n",
    "    }\n",
    "\n",
    "\n",
    "def extract_province_from_detail(job_url: str, headers: dict) -> tuple[str, str]:\n",
    "    try:\n",
    "        response = requests.get(job_url, headers=headers, timeout=30)\n",
    "        response.raise_for_status()\n",
    "    except Exception:\n",
    "        return \"\", \"\"\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    province_links = soup.select('a[id^=\"company-1-tag-\"][href*=\"province=\"]')\n",
    "\n",
    "    for link in province_links:\n",
    "        href = link.get(\"href\", \"\")\n",
    "        name = clean_text(link.get_text(\" \", strip=True))\n",
    "\n",
    "        if not href or not name:\n",
    "            continue\n",
    "\n",
    "        province_value = parse_qs(urlparse(href).query).get(\"province\", [\"\"])[0]\n",
    "        if not province_value or not province_value.isdigit():\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            code = normalize_province_code(province_value)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "        return code, name\n",
    "\n",
    "    return \"\", \"\"\n",
    "\n",
    "\n",
    "def scrape_jobthai_all_locations(\n",
    "    search_url: str,\n",
    "    max_pages: int = 10,\n",
    "    sleep_seconds: float = 1.0,\n",
    "    detail_sleep_seconds: float = 0.5,\n",
    ") -> pd.DataFrame:\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\",\n",
    "        \"Accept-Language\": \"th-TH,th;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
    "    }\n",
    "\n",
    "    keyword = parse_qs(urlparse(search_url).query).get(\"keyword\", [\"\"])[0]\n",
    "    keyword_groups = keyword_match_groups_from_query(keyword)\n",
    "\n",
    "    all_rows = []\n",
    "    seen_urls = set()\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"[Search] Starting page crawl: max_pages={max_pages}\")\n",
    "\n",
    "    for page_num in range(1, max_pages + 1):\n",
    "        page_url = update_query_in_url(search_url, page=page_num)\n",
    "        print(f\"[Search] Page {page_num}/{max_pages} -> request\")\n",
    "\n",
    "        response = requests.get(page_url, headers=headers, timeout=30)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        if \"nodata=true\" in response.url.lower():\n",
    "            print(f\"[Search] Page {page_num}/{max_pages} -> nodata=true, stopping\")\n",
    "            break\n",
    "\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        title_nodes = soup.select('h2[id^=\"job-card-item-\"]')\n",
    "        print(f\"[Search] Page {page_num}/{max_pages} -> found cards: {len(title_nodes)}\")\n",
    "\n",
    "        page_rows = []\n",
    "        for title_node in title_nodes:\n",
    "            row = parse_card_from_title(\n",
    "                title_node,\n",
    "                page_num=page_num,\n",
    "                keyword=keyword,\n",
    "            )\n",
    "            if not row[\"job_url\"]:\n",
    "                continue\n",
    "            if not title_matches_keyword(row[\"job_title\"], keyword_groups):\n",
    "                continue\n",
    "            if row[\"job_url\"] in seen_urls:\n",
    "                continue\n",
    "\n",
    "            seen_urls.add(row[\"job_url\"])\n",
    "            page_rows.append(row)\n",
    "\n",
    "        if not page_rows:\n",
    "            print(f\"[Search] Page {page_num}/{max_pages} -> no keyword matches, stopping\")\n",
    "            break\n",
    "\n",
    "        all_rows.extend(page_rows)\n",
    "        print(\n",
    "            f\"[Search] Page {page_num}/{max_pages} -> kept {len(page_rows)} | cumulative={len(all_rows)}\"\n",
    "        )\n",
    "\n",
    "        if sleep_seconds > 0:\n",
    "            time.sleep(sleep_seconds)\n",
    "\n",
    "    total_details = len(all_rows)\n",
    "    print(f\"[Detail] Starting province lookup for {total_details} jobs\")\n",
    "\n",
    "    for index, row in enumerate(all_rows, start=1):\n",
    "        province_code, province_name = extract_province_from_detail(row[\"job_url\"], headers=headers)\n",
    "        row[\"province_code\"] = province_code\n",
    "        row[\"province_name\"] = province_name\n",
    "\n",
    "        if total_details <= 50 or index % 10 == 0 or index == total_details:\n",
    "            percent = (index / total_details) * 100 if total_details else 100\n",
    "            print(f\"[Detail] {index}/{total_details} ({percent:.1f}%)\")\n",
    "\n",
    "        if detail_sleep_seconds > 0:\n",
    "            time.sleep(detail_sleep_seconds)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"[Done] Completed in {elapsed:.1f}s\")\n",
    "\n",
    "    df = pd.DataFrame(all_rows)\n",
    "\n",
    "    if not df.empty:\n",
    "        df = df[\n",
    "            [\n",
    "                \"keyword\",\n",
    "                \"province_code\",\n",
    "                \"province_name\",\n",
    "                \"page\",\n",
    "                \"job_title\",\n",
    "                \"company\",\n",
    "                \"location\",\n",
    "                \"salary\",\n",
    "                \"posted_date\",\n",
    "                \"job_url\",\n",
    "                \"raw_text\",\n",
    "            ]\n",
    "        ].drop_duplicates(subset=[\"job_url\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "jobs_df = scrape_jobthai_all_locations(\n",
    "    SEARCH_URL,\n",
    "    max_pages=MAX_PAGES,\n",
    "    sleep_seconds=SLEEP_SECONDS,\n",
    "    detail_sleep_seconds=DETAIL_SLEEP_SECONDS,\n",
    ")\n",
    "print(f\"\\nTotal unique jobs: {len(jobs_df)}\")\n",
    "\n",
    "output_path = Path(OUTPUT_CSV)\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "jobs_df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"Saved CSV: {output_path.resolve()}\")\n",
    "\n",
    "jobs_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
