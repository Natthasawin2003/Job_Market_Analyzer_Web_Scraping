{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c788434d",
   "metadata": {},
   "source": [
    "# JobThai Web Scraper (Data Scientist)\n",
    "\n",
    "This notebook scrapes JobThai search results for **Data Scientist**, extracts structured fields, and saves them to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d932af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1: collected 20 jobs\n",
      "Page 2: collected 20 jobs\n",
      "Page 3: collected 20 jobs\n",
      "Page 4: collected 20 jobs\n",
      "Page 5: collected 20 jobs\n",
      "Page 6: collected 17 jobs\n",
      "Page 7: no jobs found, stopping.\n",
      "Total unique jobs: 117\n",
      "Saved CSV: G:\\Users\\Moss\\Documents\\PYTHON_PROJECT\\Job_Market_Analyzer_Web_Scraping\\Moss\\jobsdb_data-scientist_jobthai_20260217.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>page</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>job_url</th>\n",
       "      <th>raw_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>บริษัท จี.เอ็ม.เอส. คอร์เปอเรชั่น จำกัด</td>\n",
       "      <td>เขตยานนาวา กรุงเทพมหานคร</td>\n",
       "      <td>25,000 - 30,000 บาท</td>\n",
       "      <td>16 ก.พ. 69</td>\n",
       "      <td>https://www.jobthai.com/th/company/job/1822474</td>\n",
       "      <td>Data Scientist บริษัท จี.เอ็ม.เอส. คอร์เปอเรชั...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Digital Dialogue Co., Ltd.</td>\n",
       "      <td></td>\n",
       "      <td>ตามโครงสร้างบริษัทฯ</td>\n",
       "      <td>16 ก.พ. 69</td>\n",
       "      <td>https://www.jobthai.com/th/company/job/1685397</td>\n",
       "      <td>Data Scientist Digital Dialogue Co., Ltd. Digi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>1</td>\n",
       "      <td>Specialist - DATA Scientist</td>\n",
       "      <td>บริษัท เคซีจี คอร์ปอเรชั่น จำกัด (มหาชน) / KCG...</td>\n",
       "      <td></td>\n",
       "      <td>ตามโครงสร้างบริษัทฯ</td>\n",
       "      <td>16 ก.พ. 69</td>\n",
       "      <td>https://www.jobthai.com/th/company/job/1848401</td>\n",
       "      <td>Specialist - DATA Scientist บริษัท เคซีจี คอร์...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Scientist – AI &amp; Research</td>\n",
       "      <td>Lief Capital Asset Management Co., Ltd.</td>\n",
       "      <td>เขตคลองสาน กรุงเทพมหานคร</td>\n",
       "      <td>ตามโครงสร้างบริษัทฯ</td>\n",
       "      <td>16 ก.พ. 69</td>\n",
       "      <td>https://www.jobthai.com/th/company/job/1584351</td>\n",
       "      <td>Data Scientist – AI &amp; Research Lief Capital As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Scientist - WFH 95% + Office 5%</td>\n",
       "      <td>THiNKNET Co., Ltd.</td>\n",
       "      <td></td>\n",
       "      <td>25,000 - 70,000 บาท</td>\n",
       "      <td>16 ก.พ. 69</td>\n",
       "      <td>https://www.jobthai.com/th/company/job/1439476</td>\n",
       "      <td>Data Scientist - WFH 95% + Office 5% THiNKNET ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Engineer (Contractor)</td>\n",
       "      <td>The Prodigy (Thailand) Co., Ltd.</td>\n",
       "      <td>เขตพญาไท กรุงเทพมหานคร</td>\n",
       "      <td>25,000 - 35,000 บาท</td>\n",
       "      <td>9 ก.พ. 69</td>\n",
       "      <td>https://www.jobthai.com/th/company/job/1821205</td>\n",
       "      <td>Data Engineer (Contractor) The Prodigy (Thaila...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>บริษัท ซาบีน่า จำกัด (มหาชน)</td>\n",
       "      <td>เขตบางกอกน้อย กรุงเทพมหานคร</td>\n",
       "      <td>ตามตกลง</td>\n",
       "      <td>16 ก.พ. 69</td>\n",
       "      <td>https://www.jobthai.com/th/company/job/1862880</td>\n",
       "      <td>Data Analyst บริษัท ซาบีน่า จำกัด (มหาชน) บริษ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>1</td>\n",
       "      <td>Network Engineer</td>\n",
       "      <td>OxygenAI (บริษัท ออมนิ ดีล จำกัด)</td>\n",
       "      <td></td>\n",
       "      <td>ตามตกลง</td>\n",
       "      <td>16 ก.พ. 69</td>\n",
       "      <td>https://www.jobthai.com/th/company/job/1815773</td>\n",
       "      <td>Network Engineer 16 ก.พ. 69 OxygenAI (บริษัท อ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>บริษัท ชับบ์สามัคคีประกันภัย จำกัด (มหาชน)</td>\n",
       "      <td>เขตหลักสี่ กรุงเทพมหานคร</td>\n",
       "      <td>ตามตกลง</td>\n",
       "      <td>16 ก.พ. 69</td>\n",
       "      <td>https://www.jobthai.com/th/company/job/1824648</td>\n",
       "      <td>Data Analyst บริษัท ชับบ์สามัคคีประกันภัย จำกั...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>1</td>\n",
       "      <td>Business Intelligence (BI) Analyst</td>\n",
       "      <td>Sasom Co., Ltd.</td>\n",
       "      <td>เขตพระโขนง กรุงเทพมหานคร</td>\n",
       "      <td>30,000 - 35,000 บาท</td>\n",
       "      <td>13 ก.พ. 69</td>\n",
       "      <td>https://www.jobthai.com/th/company/job/1842618</td>\n",
       "      <td>Business Intelligence (BI) Analyst Sasom Co., ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          keyword  page                             job_title  \\\n",
       "0  Data Scientist     1                        Data Scientist   \n",
       "1  Data Scientist     1                        Data Scientist   \n",
       "2  Data Scientist     1           Specialist - DATA Scientist   \n",
       "3  Data Scientist     1        Data Scientist – AI & Research   \n",
       "4  Data Scientist     1  Data Scientist - WFH 95% + Office 5%   \n",
       "5  Data Scientist     1            Data Engineer (Contractor)   \n",
       "6  Data Scientist     1                          Data Analyst   \n",
       "7  Data Scientist     1                      Network Engineer   \n",
       "8  Data Scientist     1                          Data Analyst   \n",
       "9  Data Scientist     1    Business Intelligence (BI) Analyst   \n",
       "\n",
       "                                             company  \\\n",
       "0            บริษัท จี.เอ็ม.เอส. คอร์เปอเรชั่น จำกัด   \n",
       "1                         Digital Dialogue Co., Ltd.   \n",
       "2  บริษัท เคซีจี คอร์ปอเรชั่น จำกัด (มหาชน) / KCG...   \n",
       "3            Lief Capital Asset Management Co., Ltd.   \n",
       "4                                 THiNKNET Co., Ltd.   \n",
       "5                   The Prodigy (Thailand) Co., Ltd.   \n",
       "6                       บริษัท ซาบีน่า จำกัด (มหาชน)   \n",
       "7                  OxygenAI (บริษัท ออมนิ ดีล จำกัด)   \n",
       "8         บริษัท ชับบ์สามัคคีประกันภัย จำกัด (มหาชน)   \n",
       "9                                    Sasom Co., Ltd.   \n",
       "\n",
       "                      location               salary posted_date  \\\n",
       "0     เขตยานนาวา กรุงเทพมหานคร  25,000 - 30,000 บาท  16 ก.พ. 69   \n",
       "1                               ตามโครงสร้างบริษัทฯ  16 ก.พ. 69   \n",
       "2                               ตามโครงสร้างบริษัทฯ  16 ก.พ. 69   \n",
       "3     เขตคลองสาน กรุงเทพมหานคร  ตามโครงสร้างบริษัทฯ  16 ก.พ. 69   \n",
       "4                               25,000 - 70,000 บาท  16 ก.พ. 69   \n",
       "5       เขตพญาไท กรุงเทพมหานคร  25,000 - 35,000 บาท   9 ก.พ. 69   \n",
       "6  เขตบางกอกน้อย กรุงเทพมหานคร              ตามตกลง  16 ก.พ. 69   \n",
       "7                                           ตามตกลง  16 ก.พ. 69   \n",
       "8     เขตหลักสี่ กรุงเทพมหานคร              ตามตกลง  16 ก.พ. 69   \n",
       "9     เขตพระโขนง กรุงเทพมหานคร  30,000 - 35,000 บาท  13 ก.พ. 69   \n",
       "\n",
       "                                          job_url  \\\n",
       "0  https://www.jobthai.com/th/company/job/1822474   \n",
       "1  https://www.jobthai.com/th/company/job/1685397   \n",
       "2  https://www.jobthai.com/th/company/job/1848401   \n",
       "3  https://www.jobthai.com/th/company/job/1584351   \n",
       "4  https://www.jobthai.com/th/company/job/1439476   \n",
       "5  https://www.jobthai.com/th/company/job/1821205   \n",
       "6  https://www.jobthai.com/th/company/job/1862880   \n",
       "7  https://www.jobthai.com/th/company/job/1815773   \n",
       "8  https://www.jobthai.com/th/company/job/1824648   \n",
       "9  https://www.jobthai.com/th/company/job/1842618   \n",
       "\n",
       "                                            raw_text  \n",
       "0  Data Scientist บริษัท จี.เอ็ม.เอส. คอร์เปอเรชั...  \n",
       "1  Data Scientist Digital Dialogue Co., Ltd. Digi...  \n",
       "2  Specialist - DATA Scientist บริษัท เคซีจี คอร์...  \n",
       "3  Data Scientist – AI & Research Lief Capital As...  \n",
       "4  Data Scientist - WFH 95% + Office 5% THiNKNET ...  \n",
       "5  Data Engineer (Contractor) The Prodigy (Thaila...  \n",
       "6  Data Analyst บริษัท ซาบีน่า จำกัด (มหาชน) บริษ...  \n",
       "7  Network Engineer 16 ก.พ. 69 OxygenAI (บริษัท อ...  \n",
       "8  Data Analyst บริษัท ชับบ์สามัคคีประกันภัย จำกั...  \n",
       "9  Business Intelligence (BI) Analyst Sasom Co., ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "from pathlib import Path\n",
    "from urllib.parse import parse_qs, urlencode, urlparse, urlunparse\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "SEARCH_URL = \"https://www.jobthai.com/th/jobs?province=01&event-page=home&event-section=search-keyword-history&keyword=Data%20Scientist&page=1&orderBy=RELEVANCE_SEARCH\"\n",
    "OUTPUT_CSV = \"jobsdb_data-scientist_jobthai_20260217.csv\"\n",
    "MAX_PAGES = 10\n",
    "SLEEP_SECONDS = 1.2\n",
    "\n",
    "\n",
    "def update_page_in_url(url: str, page: int) -> str:\n",
    "    parsed = urlparse(url)\n",
    "    query = parse_qs(parsed.query)\n",
    "    query[\"page\"] = [str(page)]\n",
    "    new_query = urlencode(query, doseq=True)\n",
    "    return urlunparse((parsed.scheme, parsed.netloc, parsed.path, parsed.params, new_query, parsed.fragment))\n",
    "\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "\n",
    "def extract_salary(text: str) -> str:\n",
    "    patterns = [\n",
    "        r\"\\d[\\d,\\s]*\\s*-\\s*\\d[\\d,\\s]*\\s*บาท\",\n",
    "        r\"\\d[\\d,\\s]*\\s*บาท\",\n",
    "        r\"ตามโครงสร้างบริษัทฯ\",\n",
    "        r\"ตามประสบการณ์\",\n",
    "        r\"ตามตกลง\",\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            return clean_text(match.group(0))\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def extract_posted_date(text: str) -> str:\n",
    "    match = re.search(r\"\\b\\d{1,2}\\s+[ก-๙A-Za-z\\.]+\\s+\\d{2}\\b\", text)\n",
    "    return clean_text(match.group(0)) if match else \"\"\n",
    "\n",
    "\n",
    "def pick_text(parent, selectors: list[str]) -> str:\n",
    "    for selector in selectors:\n",
    "        element = parent.select_one(selector)\n",
    "        if element:\n",
    "            text = clean_text(element.get_text(\" \", strip=True))\n",
    "            if text:\n",
    "                return text\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def guess_location(lines: list[str], title: str, company: str, salary: str) -> str:\n",
    "    priority_keywords = [\"เขต\", \"กรุงเทพ\", \"จังหวัด\", \"อำเภอ\", \"อ.\", \"ต.\"]\n",
    "    transit_keywords = [\"BTS\", \"MRT\", \"SRT\", \"BRT\", \"Airport Rail Link\"]\n",
    "\n",
    "    for line in lines:\n",
    "        if line in {title, company, salary}:\n",
    "            continue\n",
    "        if any(keyword in line for keyword in priority_keywords):\n",
    "            return line\n",
    "\n",
    "    for line in lines:\n",
    "        if line in {title, company, salary}:\n",
    "            continue\n",
    "        if any(keyword in line for keyword in transit_keywords):\n",
    "            return line\n",
    "\n",
    "    if salary and salary in lines:\n",
    "        salary_idx = lines.index(salary)\n",
    "        for idx in range(salary_idx - 1, -1, -1):\n",
    "            candidate = lines[idx]\n",
    "            if candidate not in {title, company}:\n",
    "                return candidate\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def parse_card_from_title(title_node, page_num: int, keyword: str) -> dict:\n",
    "    title = clean_text(title_node.get_text(\" \", strip=True))\n",
    "\n",
    "    anchor = title_node.find_parent(\"a\", href=True)\n",
    "    href = anchor.get(\"href\", \"\") if anchor else \"\"\n",
    "    job_url = href if href.startswith(\"http\") else f\"https://www.jobthai.com{href}\"\n",
    "\n",
    "    card = anchor if anchor is not None else title_node\n",
    "\n",
    "    company = pick_text(card, [\n",
    "        'span[id^=\"job-list-company-name-\"]',\n",
    "        'h2.ohgq7e-0.enAWkF',\n",
    "    ])\n",
    "\n",
    "    location = pick_text(card, [\n",
    "        \"h3#location-text\",\n",
    "        \"h3.location-text\",\n",
    "    ])\n",
    "\n",
    "    salary = pick_text(card, [\n",
    "        \"span.salary-text\",\n",
    "        \"div.msklqa-20\",\n",
    "        \"div.msklqa-17\",\n",
    "    ])\n",
    "\n",
    "    posted_date = pick_text(card, [\n",
    "        \"span.msklqa-9\",\n",
    "    ])\n",
    "\n",
    "    raw_lines = [clean_text(x) for x in card.get_text(\"\\n\", strip=True).splitlines() if clean_text(x)]\n",
    "    raw_text = clean_text(\" \".join(raw_lines))\n",
    "\n",
    "    if not salary:\n",
    "        salary = extract_salary(raw_text)\n",
    "    if not posted_date:\n",
    "        posted_date = extract_posted_date(raw_text)\n",
    "    if not location:\n",
    "        location = guess_location(raw_lines, title=title, company=company, salary=salary)\n",
    "\n",
    "    return {\n",
    "        \"keyword\": keyword,\n",
    "        \"page\": page_num,\n",
    "        \"job_title\": title,\n",
    "        \"company\": company,\n",
    "        \"location\": location,\n",
    "        \"salary\": salary,\n",
    "        \"posted_date\": posted_date,\n",
    "        \"job_url\": job_url,\n",
    "        \"raw_text\": raw_text,\n",
    "    }\n",
    "\n",
    "\n",
    "def scrape_jobthai(search_url: str, max_pages: int = 10, sleep_seconds: float = 1.0) -> pd.DataFrame:\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\",\n",
    "        \"Accept-Language\": \"th-TH,th;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
    "    }\n",
    "\n",
    "    keyword = parse_qs(urlparse(search_url).query).get(\"keyword\", [\"\"])[0]\n",
    "    all_rows = []\n",
    "    seen_urls = set()\n",
    "\n",
    "    for page_num in range(1, max_pages + 1):\n",
    "        page_url = update_page_in_url(search_url, page_num)\n",
    "        response = requests.get(page_url, headers=headers, timeout=30)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        title_nodes = soup.select('h2[id^=\"job-card-item-\"]')\n",
    "\n",
    "        page_rows = []\n",
    "        for title_node in title_nodes:\n",
    "            row = parse_card_from_title(title_node, page_num=page_num, keyword=keyword)\n",
    "            if not row[\"job_url\"]:\n",
    "                continue\n",
    "            if row[\"job_url\"] in seen_urls:\n",
    "                continue\n",
    "            seen_urls.add(row[\"job_url\"])\n",
    "            page_rows.append(row)\n",
    "\n",
    "        if not page_rows:\n",
    "            print(f\"Page {page_num}: no jobs found, stopping.\")\n",
    "            break\n",
    "\n",
    "        all_rows.extend(page_rows)\n",
    "        print(f\"Page {page_num}: collected {len(page_rows)} jobs\")\n",
    "\n",
    "        if sleep_seconds > 0:\n",
    "            time.sleep(sleep_seconds)\n",
    "\n",
    "    df = pd.DataFrame(all_rows)\n",
    "\n",
    "    if not df.empty:\n",
    "        df = df[\n",
    "            [\n",
    "                \"keyword\",\n",
    "                \"page\",\n",
    "                \"job_title\",\n",
    "                \"company\",\n",
    "                \"location\",\n",
    "                \"salary\",\n",
    "                \"posted_date\",\n",
    "                \"job_url\",\n",
    "                \"raw_text\",\n",
    "            ]\n",
    "        ].drop_duplicates(subset=[\"job_url\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "jobs_df = scrape_jobthai(SEARCH_URL, max_pages=MAX_PAGES, sleep_seconds=SLEEP_SECONDS)\n",
    "print(f\"Total unique jobs: {len(jobs_df)}\")\n",
    "\n",
    "output_path = Path(OUTPUT_CSV)\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "jobs_df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"Saved CSV: {output_path.resolve()}\")\n",
    "\n",
    "jobs_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
