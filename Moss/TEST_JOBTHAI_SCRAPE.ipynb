{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c788434d",
   "metadata": {},
   "source": [
    "# JobThai Web Scraper (Data Scientist)\n",
    "\n",
    "This notebook scrapes JobThai search results for **Data Scientist**, extracts structured fields, and saves them to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d932af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Search] Starting page crawl: max_pages=10\n",
      "[Search] Page 1/10 -> request\n",
      "[Search] Page 1/10 -> found cards: 20\n",
      "[Search] Page 1/10 -> kept 20 | cumulative=20\n",
      "[Search] Page 2/10 -> request\n",
      "[Search] Page 2/10 -> found cards: 20\n",
      "[Search] Page 2/10 -> kept 20 | cumulative=40\n",
      "[Search] Page 3/10 -> request\n",
      "[Search] Page 3/10 -> found cards: 20\n",
      "[Search] Page 3/10 -> kept 20 | cumulative=60\n",
      "[Search] Page 4/10 -> request\n",
      "[Search] Page 4/10 -> found cards: 20\n",
      "[Search] Page 4/10 -> kept 2 | cumulative=62\n",
      "[Search] Page 5/10 -> request\n",
      "[Search] Page 5/10 -> found cards: 20\n",
      "[Search] Page 5/10 -> no keyword matches, stopping\n",
      "[Detail] Starting detail extraction for 62 jobs\n",
      "[Detail] 10/62 (16.1%)\n",
      "[Detail] 20/62 (32.3%)\n",
      "[Detail] 30/62 (48.4%)\n",
      "[Detail] 40/62 (64.5%)\n",
      "[Detail] 50/62 (80.6%)\n",
      "[Detail] 60/62 (96.8%)\n",
      "[Detail] 62/62 (100.0%)\n",
      "[Done] Completed in 124.1s\n",
      "\n",
      "Total unique jobs: 62\n",
      "Saved CSV: G:\\Users\\Moss\\Documents\\PYTHON_PROJECT\\Job_Market_Analyzer_Web_Scraping\\Moss\\jobthai_data-analyst_20260218.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "keyword",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "province_code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "province_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "page",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "job_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "company",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "location",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "salary",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "posted_date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "raw_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_detail_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_qualification_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "matched_skills",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "matched_skill_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "skill_python",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "skill_sql",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "skill_excel",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "skill_power_bi",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "skill_tableau",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "skill_r",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "skill_pandas",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "skill_numpy",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "skill_spark",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "skill_aws",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "skill_azure",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "skill_gcp",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "skill_machine_learning",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "skill_deep_learning",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "skill_llm",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "dffc7f6a-af12-43d7-b138-1a1c5cf451be",
       "rows": [
        [
         "0",
         "Data Analyst",
         "01",
         "กรุงเทพมหานคร",
         "1",
         "Data Analyst",
         "บริษัท เอฟซีซี เซอร์วิสเซส จำกัด",
         "MRT ภาวนา",
         "17,000 - 22,000 บาท",
         "17 ก.พ. 69",
         "https://www.jobthai.com/th/job/1755307",
         "Data Analyst บริษัท เอฟซีซี เซอร์วิสเซส จำกัด บริษัท เอฟซีซี เซอร์วิสเซส จำกัด รับสมัครด่วน MRT ภาวนา 17,000 - 22,000 บาท 17 ก.พ. 69",
         "** ส่ง resume เพื่อสมัครงานทาง Line ID: fcchr เท่านั้น ** - จัดการและสรุปข้อมูลจากฐานข้อมูล เพื่อจัดทำรายงานและนำเสนอข้อมูลให้บุคคลที่เกี่ยวข้อง - ออกแบบและปรับปรุงรายงานให้เหมาะสมกับข้อมูลและลักษณะของโปรเจกต์งานที่ได้รับมอบหมาย - จัดเตรียมเอกสารที่เกี่ยวข้องกับการตรวจสอบงานภายในฝ่าย IT และรายงานผลต่อผู้บังคับบัญชา - งาน support อื่น ๆ ที่เกี่ยวข้องกับฝ่าย IT ตามที่ได้รับมอบหมาย ประเภทสัญญาจ้าง : สัญญาจ้างประจำ ลักษณะการทำงาน : on site วันและเวลาทำงาน : วันจันทร์-วันศุกร์ เวลา 09.00 - 18.30 น.",
         "คุณสมบัติผู้สมัคร เพศหญิง อายุ 21 ปีขึ้นไป จบการศึกษาระดับปริญญาตรี ด้านเทคโนโลยีสารสนเทศ หรือสาขาวิชาที่เกี่ยวข้อง เช่น สถิติประยุกต์, คณิตศาสตร์ประยุกต์, ครุศาสตร์ (คอมพิวเตอร์) ชอบงานด้านข้อมูล และมีความสามารถในการวิเคราะห์ข้อมูลได้เป็นอย่างดี มีความรู้และใช้งานระบบฐานข้อมูล MS SQL Server, MySQL, MS Access ได้เป็นอย่างดี มีความรู้และใช้งานโปรแกรม MS Office (โดยเฉพาะ Excel) ได้เป็นอย่างดี มีความละเอียดรอบคอบสูง ใส่ใจกับความถูกต้องของข้อมูล หากมีประสบการณ์ในสายงาน Data Analytics อย่างน้อย 1 ปีขึ้นไป จะได้รับการพิจารณาเป็นพิเศษ หากเป็นนักศึกษาจบใหม่ เคยมีประสบการณ์ในการใช้โปรแกรม MS SQL Server, MySQL และ Excel จะได้รับการพิจารณาเป็นพิเศษ หากเริ่มงานได้ทันที จะได้รับการพิจารณาเป็นพิเศษ",
         "sql|excel",
         "2",
         "0",
         "1",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "1",
         "Data Analyst",
         "32",
         "จ.พระนครศรีอยุธยา",
         "1",
         "Data Analyst",
         "Tech Solution AI Co., Ltd.",
         "อ.วังน้อย จ.พระนครศรีอยุธยา",
         "ตามตกลง",
         "18 ก.พ. 69",
         "https://www.jobthai.com/th/job/1857706",
         "Data Analyst Tech Solution AI Co., Ltd. Tech Solution AI Co., Ltd. รับสมัครด่วน อ.วังน้อย จ.พระนครศรีอยุธยา ตามตกลง 18 ก.พ. 69",
         "1. ออกแบบ Dashboard และ Data Visualization ให้เข้าใจง่ายและใช้งานได้จริง 2. ออกแบบ UX/UI สำหรับรายงานข้อมูล (Dashboard / Report / System View) 3. แปลง Requirement จากผู้ใช้งานให้เป็นภาพข้อมูลที่เหมาะสม 4. ทำงานร่วมกับทีมธุรกิจ ทีม IT และผู้ใช้ระบบ 5. ปรับปรุงรูปแบบ Dashboard ให้ดูทันสมัย ใช้งานง่าย และตอบโจทย์องค์กร 6. เขียนโค้ดหรือสคริปต์พื้นฐานเพื่อเชื่อมข้อมูลหรือปรับการแสดงผล (ไม่ต้องเชี่ยวชาญมาก) 7. ทดลอง พัฒนา และต่อยอดงานด้าน Data ผ่านกระบวนการ R&D 8. เรียนรู้เครื่องมือใหม่ ๆ ด้าน Data และ Visualization อย่างต่อเนื่อง",
         "คุณสมบัติผู้สมัคร วุฒิปริญญาตรีขึ้นไป สายวิศวกรรม / IT / คอมพิวเตอร์ / Data / วิทยาศาสตร์ / หรือสาขาที่เกี่ยวข้อง เพศ ชาย-หญิง หากเป็นสายวิศวที่มาเรียนด้าน Data จะพิจารณาเป็นพิเศษ มีความเข้าใจด้าน Data Visualization มากกว่าการทำ Data Analytics เชิงลึก เข้าใจหลัก UX/UI สำหรับ Dashboard และการนำเสนอข้อมูล สามารถเขียนโค้ดได้ระดับพื้นฐาน เช่น SQL/Python/JavaScript/หรือ Script อื่น ๆ ใช้เครื่องมือ Data Visualization เช่น Power BI/Tableau/Looker Studio/หรือเครื่องมือใกล้เคียง",
         "python|sql|power_bi|tableau|r",
         "5",
         "1",
         "1",
         "0",
         "1",
         "1",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "2",
         "Data Analyst",
         "01",
         "กรุงเทพมหานคร",
         "1",
         "Data Analyst",
         "บริษัท เมืองไทย แคปปิตอล จำกัด (มหาชน)",
         "MRT บางพลัด",
         "22,000 - 23,000 บาท",
         "18 ก.พ. 69",
         "https://www.jobthai.com/th/job/1752582",
         "Data Analyst บริษัท เมืองไทย แคปปิตอล จำกัด (มหาชน) บริษัท เมืองไทย แคปปิตอล จำกัด (มหาชน) MRT บางพลัด 22,000 - 23,000 บาท สัมภาษณ์งานออนไลน์ 18 ก.พ. 69",
         "- รวบรวม วิเคราะห์ และ แปลผลข้อมูลจากแหล่งต่างๆ เพื่อสนับสนุนการตัดสินใจทางธุรกิจ - ออกแบบและพัฒนาDashboard - ค้นหาแนวโน้ม รูปแบบ และข้อมูลเชิงลึก เพื่อนำไปใช้ในเชิงกลยุทธ์ - ตรวจสอบความถูกต้องของข้อมูล พร้อมปรับปรุงคุณภาพของข้อมูลให้มีมาตรฐาน - นำเสนอข้อมูลเชิงลึกแก่ผู้บริหารและทีมที่เกี่ยวข้องในรูปแบบที่เข้าใจง่าย - งานอื่นๆที่ได้รับมอบหมาย",
         "คุณสมบัติผู้สมัคร อายุไม่เกิน 26 ปี วุฒิการศึกษาระดับปริญญาตรีขึ้นไป คณะวิศวกรรมศาสตร์หรือที่เกี่ยวข้อง เกรดเฉลี่ย 3.00 ขึ้นไป มีทักษะการใช้ภาษา SQL (ถ้ามีจะพิจารณาเป็นพิเศษ) มีทักษะการใช้โปรแกรม Microsoft Office เช่น Microsoft Excel ในระดับดีเยี่ยม มีทักษะการวิเคราะห์ คำนวณและการนำเสนอข้อมูล รวมไปถึงความรู้ด้านสถิติ ทำงานภายใต้แรงกดดันได้ดี มีความละเอียด รอบคอบ",
         "sql|excel",
         "2",
         "0",
         "1",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "3",
         "Data Analyst",
         "01",
         "กรุงเทพมหานคร",
         "1",
         "Data Analyst",
         "S45 Clinic",
         "BTS พร้อมพงษ์",
         "ตามตกลง",
         "18 ก.พ. 69",
         "https://www.jobthai.com/th/job/1844306",
         "Data Analyst S45 Clinic S45 Clinic BTS พร้อมพงษ์ ตามตกลง สัมภาษณ์งานออนไลน์ 18 ก.พ. 69",
         "1.วิเคราะห์ข้อมูลเชิงลึกจากหลายแหล่ง (Sales / Marketing / Operation / Clinic Data) 2.สร้าง Report & Dashboard เพื่อสนับสนุนการตัดสินใจของผู้บริหาร 3.แปลงตัวเลขให้เป็น Insight และข้อเสนอเชิงกลยุทธ์ 4.ตรวจสอบความถูกต้องและคุณภาพของข้อมูล 5.ทำงานร่วมกับหลายทีม เพื่อพัฒนาประสิทธิภาพธุรกิจ",
         "คุณสมบัติผู้สมัคร มีประสบการณ์ด้าน Data Analysis / Business Intelligence ใช้ Excel / Google Sheets ขั้น Advance ได้ดี ใช้ BI Tools เช่น Power BI, Looker, Tableau เขียน SQL ดึงและจัดการข้อมูลได้ เข้าใจธุรกิจ (โดยเฉพาะ Clinic / Hospital จะพิจารณาเป็นพิเศษ) สื่อสารข้อมูลซับซ้อนให้เข้าใจง่าย รอบคอบ รับผิดชอบ และรักษาความลับข้อมูลได้ดี",
         "sql|excel|power_bi|tableau",
         "4",
         "0",
         "1",
         "1",
         "1",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "4",
         "Data Analyst",
         "28",
         "จ.ปทุมธานี",
         "1",
         "Data Analyst",
         "บริษัท ดูโฮม จำกัด (มหาชน)",
         "อ.เมืองปทุมธานี จ.ปทุมธานี",
         "18,000 - 30,000 บาท",
         "18 ก.พ. 69",
         "https://www.jobthai.com/th/job/1809674",
         "Data Analyst บริษัท ดูโฮม จำกัด (มหาชน) บริษัท ดูโฮม จำกัด (มหาชน) อ.เมืองปทุมธานี จ.ปทุมธานี 18,000 - 30,000 บาท สัมภาษณ์งานออนไลน์ 18 ก.พ. 69",
         "รวบรวมและปรับปรุงข้อมูลดิบจากหลากหลายช่องทาง ตรวจสอบความถูกต้องและความครบถ้วนของข้อมูล พร้อมดำเนินการตรวจสอบคุณภาพและแก้ไขข้อผิดพลาดที่พบ วิเคราะห์ข้อมูลเชิงลึกเพื่อค้นหาข้อสรุปและแนวโน้ม โดยใช้วิธีการทางสถิติ และนำเสนอข้อเสนอแนะเชิงปฏิบัติได้จริงเพื่อสนับสนุนการตัดสินใจ จัดทำรายงานมาตรฐานและแดชบอร์ด ที่แสดงตัวชี้วัดด้านประสิทธิภาพให้เห็นภาพรวมได้อย่างชัดเจนและเข้าใจง่ายสำหรับผู้ใช้งานหลัก ดูแลและพัฒนาระบบรายงานอัตโนมัติ เพื่อเพิ่มประสิทธิภาพและความรวดเร็วของกระบวนการวิเคราะห์ข้อมูล ประสานงานอย่างใกล้ชิดกับทีมงานข้ามสายงาน เพื่อทำความเข้าใจความต้องการด้านข้อมูลและให้การสนับสนุนด้านการวิเคราะห์ สร้างวัฒนธรรมการทำงานที่ขับเคลื่อนด้วยข้อมูล ทำงานร่วมกับผู้นำทางธุรกิจ เพื่อค้นหาโอกาสในการปรับปรุงกระบวนการ โดยใช้ข้อมูลเชิงลึกเป็นพื้นฐาน",
         "คุณสมบัติผู้สมัคร ปริญญาตรี สาขาสถิติ , เศรษศาสตร์ , การตลาด, บริหารธุรกิจ หรือที่เกี่ยวข้อง มีประสบการณ์ทำงานด้านการวิเคราะห์ข้อมูล หรือในตำแหน่งที่เกี่ยวข้อง มีความเชี่ยวชาญขั้นสูงในการใช้ Power BI และสามารถเขียน DAX ได้ มีความสามารถในการใช้เครื่องมือวิเคราะห์ข้อมูลและภาษาโปรแกรม เช่น SQL, Python มีความรู้ด้านวิธีการทางสถิติและการนำเสนอข้อมูลด้วยภาพ (Data Visualization) มีความเชี่ยวชาญขั้นสูงในการใช้ Power BI และสามารถเขียน DAX ได้",
         "python|sql|power_bi",
         "3",
         "1",
         "1",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "5",
         "Data Analyst",
         "01",
         "กรุงเทพมหานคร",
         "1",
         "Data Analyst",
         "บริษัท ซาบีน่า จำกัด (มหาชน)",
         "เขตบางกอกน้อย กรุงเทพมหานคร",
         "ตามตกลง",
         "18 ก.พ. 69",
         "https://www.jobthai.com/th/job/1862880",
         "Data Analyst บริษัท ซาบีน่า จำกัด (มหาชน) บริษัท ซาบีน่า จำกัด (มหาชน) เขตบางกอกน้อย กรุงเทพมหานคร ตามตกลง Hybrid Work สัมภาษณ์งานออนไลน์ 18 ก.พ. 69",
         "- พัฒนาโมเดล Machine Learning (Classification, Regression, Clustering, Time-series) - ออกแบบ Feature Engineering และเลือกใช้ Algorithm ที่เหมาะสม - ประเมินและปรับปรุงโมเดลเพื่อเพิ่มความแม่นยำ - เตรียมและทำความสะอาดข้อมูล (Data Preparation / Cleansing) จากหลายแหล่ง - จัดทำรายงานและสร้าง Dashboard ด้วย Power BI - ปฏิบัติงานอื่น ๆ ตามที่ได้รับมอบหมาย",
         "คุณสมบัติผู้สมัคร เพศชาย/หญิง อายุ 23–35 ปี สำเร็จการศึกษาระดับปริญญาตรีหรือโท สาขา Data Science, Computer Science, Statistics, Applied Mathematics หรือสาขาที่เกี่ยวข้อง มีประสบการณ์ด้าน Machine Learning / Data Science อย่างน้อย 1 ปี มีทักษะด้าน Data Modeling, Data Preparation และ Data Cleansing มีทักษะการเขียนโปรแกรมภาษา Python มีพื้นฐาน SQL และ Power BI สามารถเข้ารับการสัมภาษณ์แบบ Onsite/Online และทำแบบทดสอบได้",
         "python|sql|power_bi|machine_learning",
         "4",
         "1",
         "1",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0"
        ],
        [
         "6",
         "Data Analyst",
         "01",
         "กรุงเทพมหานคร",
         "1",
         "Data Analyst",
         "บริษัท ชับบ์สามัคคีประกันภัย จำกัด (มหาชน)",
         "เขตหลักสี่ กรุงเทพมหานคร",
         "ตามตกลง",
         "18 ก.พ. 69",
         "https://www.jobthai.com/th/job/1824648",
         "Data Analyst บริษัท ชับบ์สามัคคีประกันภัย จำกัด (มหาชน) บริษัท ชับบ์สามัคคีประกันภัย จำกัด (มหาชน) เขตหลักสี่ กรุงเทพมหานคร ตามตกลง 18 ก.พ. 69",
         "Work closely with Conservation Team (Call Center for retention) with following support. •Develop, maintain, and enhance dashboards to track retention metrics, policy cancellation rates, and other key performance indicators. •Conduct in-depth data analysis to identify trends, root causes, and opportunities for improving policy retention. •Prepare regular and ad-hoc reports for management and Conservation teams, highlighting actionable insights and recommendations. •Collaborate with IT, data, and business teams to ensure the accuracy, consistency, and integrity of data used for analysis and reporting. •Support the design, implementation, and evaluation of retention strategies through quantitative analysis. •Accurately calculate and validate incentive payments for Conservation staff in accordance with the incentive scheme. •Document analytical methodologies and maintain up-to-date process documentation. •Stay informed of industry best practices, data tools, and Chubb’s insurance products to enhance analytical capabilities.",
         "คุณสมบัติผู้สมัคร Bachelor’s degree in Business Analytics, Statistics, Data Science, or a related field. Ability to communicate complex findings clearly to non-technical stakeholders. Self-motivated and able to manage multiple priorities in a fast-paced environment. Advanced proficiency in data visualization tools (e.g., Tableau, Power BI) and Excel. Strong analytical, problem-solving, and quantitative skills. Minimum 2 years of experience in operations analysis, business intelligence, or data analytics (insurance industry experience preferred). Experience with SQL or other data querying languages is an advantage.",
         "sql|excel|power_bi|tableau",
         "4",
         "0",
         "1",
         "1",
         "1",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "7",
         "Data Analyst",
         "01",
         "กรุงเทพมหานคร",
         "1",
         "Data Analyst",
         "บริษัท เริ่มใหม่ จำกัด",
         "เขตสายไหม กรุงเทพมหานคร",
         "ตามความสามารถและประสบการณ์",
         "18 ก.พ. 69",
         "https://www.jobthai.com/th/job/1643374",
         "Data Analyst บริษัท เริ่มใหม่ จำกัด บริษัท เริ่มใหม่ จำกัด เขตสายไหม กรุงเทพมหานคร ตามความสามารถและประสบการณ์ 18 ก.พ. 69",
         "- รวบรวมและวิเคราะห์ข้อมูล สถิติ คู่แข่ง เพื่อจัดทำแผนการขายให้สอดคล้องกับข้อมูล - วิเคราะห์ช่องทางและคู่แข่งทางการตลาด - จัดทำ Report ในรูปแบบ Dashboard หรือ Visualize ที่สามารถสื่อสารให้เข้าใจได้โดยง่ายและชัดเจน - จัดทำแผน และพัฒนาระบบฐานข้อมูลและรายงาน เพื่อใช้ในการวิเคราะห์ ติดตามผลการปฏิบัติงานได้อย่างมีประสิทธิภาพ - ร่วมวางแผน พัฒนา และปรับปรุงการทำการตลาดขององค์กร - บริหารการยิงโฆษณาออนไลน์ ในช่องทางต่างๆได้ - ประสานงานกับแผนกอื่นๆ เพื่อให้ได้ผลลัพธ์ตามที่ได้วางไว้ - มีความเข้าใจในธุรกิจ และวิเคราะห์ข้อมูลเพื่อตอบโจทย์ในทางธุรกิจได้ สมัครด่วนผ่านช่องทาง link นี้ได้เลยค่ะ : https://jobs.techsauce.co/บริษัทเริ่มใหม่จำกัด",
         "คุณสมบัติผู้สมัคร อายุ 22-35 ปี ไม่จำกัดเพศ วุฒิการศึกษาระดับปริญญาตรีขึ้นไป มีประสบการณ์ในตำแหน่งงาน 1 - 5 ปี มีประสบการณ์ในสายงาน Data Analyst Management มีทักษะในการสื่อสารและความเข้าใจในงาน สามารถทำงานเป็นทีมได้ เข้าใจเครื่องมือการตลาดดิจิทอล เช่น Google Analytics, Google Tag Manager เข้าใจเรื่องสถิติ มีประสบการณ์ในการสรุปผล เช่น Excel, Power BI สามารถใช้งานเครื่องมือในการสร้างรายงาน สร้างDashboardเช่น Power BI, Tableau , Qlik",
         "excel|power_bi|tableau",
         "3",
         "0",
         "0",
         "1",
         "1",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "8",
         "Data Analyst",
         "01",
         "กรุงเทพมหานคร",
         "1",
         "Data Analyst / Business Data Analyst",
         "บริษัท ฟังก์ชั่น อินเตอร์เนชั่นแนล จำกัด (มหาชน)",
         "เขตคลองสามวา กรุงเทพมหานคร",
         "20,000 - 30,000 บาท",
         "17 ก.พ. 69",
         "https://www.jobthai.com/th/job/1854175",
         "Data Analyst / Business Data Analyst 17 ก.พ. 69 บริษัท ฟังก์ชั่น อินเตอร์เนชั่นแนล จำกัด (มหาชน) บริษัท ฟังก์ชั่น อินเตอร์เนชั่นแนล จำกัด (มหาชน) เขตคลองสามวา กรุงเทพมหานคร 20,000 - 30,000 บาท",
         "•วิเคราะห์ข้อมูลเชิงลึกจากข้อมูลดิบ (Raw Data) ขององค์กร เช่น oข้อมูลสินค้าและสต๊อก oสินค้า Aging / สินค้าคงค้าง oข้อมูลการขาย การกระจายสินค้า และแนวโน้มทางธุรกิจ •แปลงข้อมูลดิบให้เป็นข้อมูลเชิงวิเคราะห์ เพื่อสนับสนุนการตัดสินใจของผู้บริหาร •ระบุประเด็นสำคัญ จุดเสี่ยง และโอกาสทางธุรกิจจากข้อมูล •จัดทำรายงานและ Dashboard เพื่อนำเสนอข้อมูลในรูปแบบที่เข้าใจง่าย •ทำงานร่วมกับฝ่ายคลังสินค้า ฝ่ายขาย จัดซื้อ และฝ่ายที่เกี่ยวข้อง •พัฒนาแนวทางการใช้ข้อมูล (Data-driven) ภายในองค์กร",
         "คุณสมบัติผู้สมัคร ปริญญาตรีขึ้นไป สาขาสถิติ, Data Science, IT, วิศวกรรม, บริหารธุรกิจ หรือสาขาที่เกี่ยวข้อง มีประสบการณ์ด้าน Data Analysis, Business Analysis หรือ Data-related อย่างน้อย 2–5 ปี สามารถทำงานกับข้อมูลดิบจำนวนมากได้ และเข้าใจโครงสร้างข้อมูล มีทักษะในการใช้เครื่องมือวิเคราะห์ข้อมูล เช่น Excel ขั้นสูง (Pivot, Power Query, Formula) SQL / Power BI / Tableau หรือเครื่องมือ Data Visualization อื่น ๆ มีทักษะการคิดเชิงวิเคราะห์ (Analytical Thinking) และมองภาพรวมทางธุรกิจได้ดี สามารถสื่อสารข้อมูลเชิงซับซ้อนให้ผู้บริหารเข้าใจได้ หากมีประสบการณ์ในธุรกิจค้าส่ง โลจิสติกส์ หรือบริหารสต๊อก จะได้รับการพิจารณาเป็นพิเศษ",
         "sql|excel|power_bi|tableau",
         "4",
         "0",
         "1",
         "1",
         "1",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0"
        ],
        [
         "9",
         "Data Analyst",
         "01",
         "กรุงเทพมหานคร",
         "1",
         "Data Analyst - BNG",
         "บริษัท เบญจจินดา โฮลดิ้ง จำกัด",
         "SRT บางเขน",
         "ตามประสบการณ์",
         "16 ก.พ. 69",
         "https://www.jobthai.com/th/job/1858004",
         "Data Analyst - BNG บริษัท เบญจจินดา โฮลดิ้ง จำกัด บริษัท เบญจจินดา โฮลดิ้ง จำกัด SRT บางเขน ตามประสบการณ์ 16 ก.พ. 69",
         "1. Data Management and Analysis: - Responsible for analyzing and processing data from various sources (both internal and external) using ETL (Extract, Transform, Load) tools to prepare data for analysis and reporting. - Ensure the accuracy of data (Data Accuracy) and perform data cleaning to remove errors, duplicates, and inconsistencies. - Design and develop reports and dashboards that communicate data insights effectively to business stakeholders using BI tools such as Power BI, Tableau, or Excel. 2. Vendor Collaboration: - Coordinate with external vendors to ensure that data delivery and services align with the terms set in the TOR (Terms of Reference) effectively. - Manage vendor meetings to align on project requirements, track deliverables, and ensure the timely delivery of projects. - Provide guidance and set the direction for vendor collaboration to meet project goals and business objectives. 3. ETL Development and Data Management: - Design and develop ETL processes for extracting, transforming, and loading data from multiple sources into a structured format for analysis. - Review and improve the ETL process to increase efficiency, reduce processing time, and ensure data is properly integrated for reporting and analysis. 4. Report and Dashboard Development: - Create reports and dashboards that meet business requirements, providing insights to business stakeholders, including executives and teams. - Present data clearly and concisely, providing decision-makers with actionable insights and supporting business decisions. 5. Learning and Adaptation: - Continuously learn new tools and technologies, including SQL, BI tools, and other data management tools. - Adapt quickly to changes in technology or business requirements, and incorporate new learning into daily work.",
         "คุณสมบัติผู้สมัคร Bachelor’s degree in Computer Science, Statistics, Data Analysis, or related field. 3-5 years of experience in a Data Analyst, BI Developer, or related role, with hands-on experience in data management and developing ETL processes. Proficiency in BI tools (e.g., Power BI, Tableau, Excel) and ETL tools (e.g., Talend, Apache Nifi) and SQL Strong understanding of the ETL/ELT process and ability to handle data integration from multiple sources. Ability to manage and lead meetings with external vendors, ensuring alignment with project timelines and goals. Proven experience in data analysis and report creation, with the ability to present data insights to stakeholders clearly. Proactive in learning new tools, technologies, and methods to stay up to date with industry changes. Experience with Big Data management or working with large datasets. Knowledge of Business Intelligence and Advanced Analytics techniques. Ability to understand and work with TOR (Terms of Reference) is a plus.",
         "sql|excel|power_bi|tableau",
         "4",
         "0",
         "1",
         "1",
         "1",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0"
        ]
       ],
       "shape": {
        "columns": 30,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>province_code</th>\n",
       "      <th>province_name</th>\n",
       "      <th>page</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>job_url</th>\n",
       "      <th>...</th>\n",
       "      <th>skill_r</th>\n",
       "      <th>skill_pandas</th>\n",
       "      <th>skill_numpy</th>\n",
       "      <th>skill_spark</th>\n",
       "      <th>skill_aws</th>\n",
       "      <th>skill_azure</th>\n",
       "      <th>skill_gcp</th>\n",
       "      <th>skill_machine_learning</th>\n",
       "      <th>skill_deep_learning</th>\n",
       "      <th>skill_llm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>01</td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>บริษัท เอฟซีซี เซอร์วิสเซส จำกัด</td>\n",
       "      <td>MRT ภาวนา</td>\n",
       "      <td>17,000 - 22,000 บาท</td>\n",
       "      <td>17 ก.พ. 69</td>\n",
       "      <td>https://www.jobthai.com/th/job/1755307</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>32</td>\n",
       "      <td>จ.พระนครศรีอยุธยา</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Tech Solution AI Co., Ltd.</td>\n",
       "      <td>อ.วังน้อย จ.พระนครศรีอยุธยา</td>\n",
       "      <td>ตามตกลง</td>\n",
       "      <td>18 ก.พ. 69</td>\n",
       "      <td>https://www.jobthai.com/th/job/1857706</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>01</td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>บริษัท เมืองไทย แคปปิตอล จำกัด (มหาชน)</td>\n",
       "      <td>MRT บางพลัด</td>\n",
       "      <td>22,000 - 23,000 บาท</td>\n",
       "      <td>18 ก.พ. 69</td>\n",
       "      <td>https://www.jobthai.com/th/job/1752582</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>01</td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>S45 Clinic</td>\n",
       "      <td>BTS พร้อมพงษ์</td>\n",
       "      <td>ตามตกลง</td>\n",
       "      <td>18 ก.พ. 69</td>\n",
       "      <td>https://www.jobthai.com/th/job/1844306</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>28</td>\n",
       "      <td>จ.ปทุมธานี</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>บริษัท ดูโฮม จำกัด (มหาชน)</td>\n",
       "      <td>อ.เมืองปทุมธานี จ.ปทุมธานี</td>\n",
       "      <td>18,000 - 30,000 บาท</td>\n",
       "      <td>18 ก.พ. 69</td>\n",
       "      <td>https://www.jobthai.com/th/job/1809674</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>01</td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>บริษัท ซาบีน่า จำกัด (มหาชน)</td>\n",
       "      <td>เขตบางกอกน้อย กรุงเทพมหานคร</td>\n",
       "      <td>ตามตกลง</td>\n",
       "      <td>18 ก.พ. 69</td>\n",
       "      <td>https://www.jobthai.com/th/job/1862880</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>01</td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>บริษัท ชับบ์สามัคคีประกันภัย จำกัด (มหาชน)</td>\n",
       "      <td>เขตหลักสี่ กรุงเทพมหานคร</td>\n",
       "      <td>ตามตกลง</td>\n",
       "      <td>18 ก.พ. 69</td>\n",
       "      <td>https://www.jobthai.com/th/job/1824648</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>01</td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>บริษัท เริ่มใหม่ จำกัด</td>\n",
       "      <td>เขตสายไหม กรุงเทพมหานคร</td>\n",
       "      <td>ตามความสามารถและประสบการณ์</td>\n",
       "      <td>18 ก.พ. 69</td>\n",
       "      <td>https://www.jobthai.com/th/job/1643374</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>01</td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst / Business Data Analyst</td>\n",
       "      <td>บริษัท ฟังก์ชั่น อินเตอร์เนชั่นแนล จำกัด (มหาชน)</td>\n",
       "      <td>เขตคลองสามวา กรุงเทพมหานคร</td>\n",
       "      <td>20,000 - 30,000 บาท</td>\n",
       "      <td>17 ก.พ. 69</td>\n",
       "      <td>https://www.jobthai.com/th/job/1854175</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>01</td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst - BNG</td>\n",
       "      <td>บริษัท เบญจจินดา โฮลดิ้ง จำกัด</td>\n",
       "      <td>SRT บางเขน</td>\n",
       "      <td>ตามประสบการณ์</td>\n",
       "      <td>16 ก.พ. 69</td>\n",
       "      <td>https://www.jobthai.com/th/job/1858004</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        keyword province_code      province_name  page  \\\n",
       "0  Data Analyst            01      กรุงเทพมหานคร     1   \n",
       "1  Data Analyst            32  จ.พระนครศรีอยุธยา     1   \n",
       "2  Data Analyst            01      กรุงเทพมหานคร     1   \n",
       "3  Data Analyst            01      กรุงเทพมหานคร     1   \n",
       "4  Data Analyst            28         จ.ปทุมธานี     1   \n",
       "5  Data Analyst            01      กรุงเทพมหานคร     1   \n",
       "6  Data Analyst            01      กรุงเทพมหานคร     1   \n",
       "7  Data Analyst            01      กรุงเทพมหานคร     1   \n",
       "8  Data Analyst            01      กรุงเทพมหานคร     1   \n",
       "9  Data Analyst            01      กรุงเทพมหานคร     1   \n",
       "\n",
       "                              job_title  \\\n",
       "0                          Data Analyst   \n",
       "1                          Data Analyst   \n",
       "2                          Data Analyst   \n",
       "3                          Data Analyst   \n",
       "4                          Data Analyst   \n",
       "5                          Data Analyst   \n",
       "6                          Data Analyst   \n",
       "7                          Data Analyst   \n",
       "8  Data Analyst / Business Data Analyst   \n",
       "9                    Data Analyst - BNG   \n",
       "\n",
       "                                            company  \\\n",
       "0                  บริษัท เอฟซีซี เซอร์วิสเซส จำกัด   \n",
       "1                        Tech Solution AI Co., Ltd.   \n",
       "2            บริษัท เมืองไทย แคปปิตอล จำกัด (มหาชน)   \n",
       "3                                        S45 Clinic   \n",
       "4                        บริษัท ดูโฮม จำกัด (มหาชน)   \n",
       "5                      บริษัท ซาบีน่า จำกัด (มหาชน)   \n",
       "6        บริษัท ชับบ์สามัคคีประกันภัย จำกัด (มหาชน)   \n",
       "7                            บริษัท เริ่มใหม่ จำกัด   \n",
       "8  บริษัท ฟังก์ชั่น อินเตอร์เนชั่นแนล จำกัด (มหาชน)   \n",
       "9                    บริษัท เบญจจินดา โฮลดิ้ง จำกัด   \n",
       "\n",
       "                      location                      salary posted_date  \\\n",
       "0                    MRT ภาวนา         17,000 - 22,000 บาท  17 ก.พ. 69   \n",
       "1  อ.วังน้อย จ.พระนครศรีอยุธยา                     ตามตกลง  18 ก.พ. 69   \n",
       "2                  MRT บางพลัด         22,000 - 23,000 บาท  18 ก.พ. 69   \n",
       "3                BTS พร้อมพงษ์                     ตามตกลง  18 ก.พ. 69   \n",
       "4   อ.เมืองปทุมธานี จ.ปทุมธานี         18,000 - 30,000 บาท  18 ก.พ. 69   \n",
       "5  เขตบางกอกน้อย กรุงเทพมหานคร                     ตามตกลง  18 ก.พ. 69   \n",
       "6     เขตหลักสี่ กรุงเทพมหานคร                     ตามตกลง  18 ก.พ. 69   \n",
       "7      เขตสายไหม กรุงเทพมหานคร  ตามความสามารถและประสบการณ์  18 ก.พ. 69   \n",
       "8   เขตคลองสามวา กรุงเทพมหานคร         20,000 - 30,000 บาท  17 ก.พ. 69   \n",
       "9                   SRT บางเขน               ตามประสบการณ์  16 ก.พ. 69   \n",
       "\n",
       "                                  job_url  ... skill_r skill_pandas  \\\n",
       "0  https://www.jobthai.com/th/job/1755307  ...       0            0   \n",
       "1  https://www.jobthai.com/th/job/1857706  ...       1            0   \n",
       "2  https://www.jobthai.com/th/job/1752582  ...       0            0   \n",
       "3  https://www.jobthai.com/th/job/1844306  ...       0            0   \n",
       "4  https://www.jobthai.com/th/job/1809674  ...       0            0   \n",
       "5  https://www.jobthai.com/th/job/1862880  ...       0            0   \n",
       "6  https://www.jobthai.com/th/job/1824648  ...       0            0   \n",
       "7  https://www.jobthai.com/th/job/1643374  ...       0            0   \n",
       "8  https://www.jobthai.com/th/job/1854175  ...       0            0   \n",
       "9  https://www.jobthai.com/th/job/1858004  ...       0            0   \n",
       "\n",
       "  skill_numpy skill_spark  skill_aws  skill_azure  skill_gcp  \\\n",
       "0           0           0          0            0          0   \n",
       "1           0           0          0            0          0   \n",
       "2           0           0          0            0          0   \n",
       "3           0           0          0            0          0   \n",
       "4           0           0          0            0          0   \n",
       "5           0           0          0            0          0   \n",
       "6           0           0          0            0          0   \n",
       "7           0           0          0            0          0   \n",
       "8           0           0          0            0          0   \n",
       "9           0           0          0            0          0   \n",
       "\n",
       "   skill_machine_learning  skill_deep_learning  skill_llm  \n",
       "0                       0                    0          0  \n",
       "1                       0                    0          0  \n",
       "2                       0                    0          0  \n",
       "3                       0                    0          0  \n",
       "4                       0                    0          0  \n",
       "5                       1                    0          0  \n",
       "6                       0                    0          0  \n",
       "7                       0                    0          0  \n",
       "8                       0                    0          0  \n",
       "9                       0                    0          0  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "from pathlib import Path\n",
    "from urllib.parse import parse_qs, urlencode, urlparse, urlunparse\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "SEARCH_URL = \"https://www.jobthai.com/th/jobs?keyword=Data%20Analyst&page=1&orderBy=RELEVANCE_SEARCH\"\n",
    "OUTPUT_CSV = \"jobthai_data-analyst_20260218.csv\"\n",
    "MAX_PAGES = 10\n",
    "SLEEP_SECONDS = 1.0\n",
    "DETAIL_SLEEP_SECONDS = 0.5\n",
    "\n",
    "SKILLS = {\n",
    "    # ---------------- Core Programming ----------------\n",
    "    \"python\": [\"python\"],\n",
    "    \"r\": [\" r \", \" r,\", \" r\\n\", \" r/\"],\n",
    "    \"java\": [\"java\"],\n",
    "    \"scala\": [\"scala\"],\n",
    "    \"c++\": [\"c++\"],\n",
    "\n",
    "    # ---------------- SQL & Databases ----------------\n",
    "    \"sql\": [\" sql \", \"mysql\", \"postgres\", \"postgresql\", \"oracle\", \"sql server\", \"mssql\", \"sqlite\"],\n",
    "    \"mongodb\": [\"mongodb\", \"mongo\"],\n",
    "    \"redis\": [\"redis\"],\n",
    "    \"cassandra\": [\"cassandra\"],\n",
    "    \"elasticsearch\": [\"elasticsearch\", \"elastic search\"],\n",
    "\n",
    "    # ---------------- Data Libraries ----------------\n",
    "    \"pandas\": [\"pandas\"],\n",
    "    \"numpy\": [\"numpy\"],\n",
    "    \"scipy\": [\"scipy\"],\n",
    "    \"sklearn\": [\"scikit-learn\", \"sklearn\"],\n",
    "\n",
    "    # ---------------- Machine Learning ----------------\n",
    "    \"machine_learning\": [\n",
    "        \"machine learning\", \"supervised\", \"unsupervised\",\n",
    "        \"random forest\", \"xgboost\", \"lightgbm\", \"catboost\"\n",
    "    ],\n",
    "\n",
    "    # ---------------- Deep Learning ----------------\n",
    "    \"deep_learning\": [\n",
    "        \"deep learning\", \"neural network\", \"cnn\", \"rnn\", \"lstm\", \"transformer\"\n",
    "    ],\n",
    "\n",
    "    # ---------------- GenAI / LLM ----------------\n",
    "    \"llm\": [\"llm\", \"large language model\"],\n",
    "    \"rag\": [\"rag\", \"retrieval augmented generation\"],\n",
    "    \"langchain\": [\"langchain\"],\n",
    "    \"openai\": [\"openai\"],\n",
    "    \"huggingface\": [\"huggingface\"],\n",
    "    \"prompt_engineering\": [\"prompt engineering\"],\n",
    "    \"vector_db\": [\"vector database\", \"pinecone\", \"faiss\", \"weaviate\", \"milvus\"],\n",
    "\n",
    "    # ---------------- Visualization / BI ----------------\n",
    "    \"excel\": [\"excel\", \"vlookup\", \"pivot table\", \"power query\"],\n",
    "    \"powerbi\": [\"power bi\", \"powerbi\", \"dax\"],\n",
    "    \"tableau\": [\"tableau\"],\n",
    "    \"matplotlib\": [\"matplotlib\"],\n",
    "    \"seaborn\": [\"seaborn\"],\n",
    "    \"plotly\": [\"plotly\"],\n",
    "\n",
    "    # ---------------- Big Data ----------------\n",
    "    \"spark\": [\"spark\", \"pyspark\"],\n",
    "    \"hadoop\": [\"hadoop\"],\n",
    "    \"kafka\": [\"kafka\"],\n",
    "\n",
    "    # ---------------- Cloud ----------------\n",
    "    \"aws\": [\"aws\", \"amazon web services\", \"s3\", \"redshift\", \"athena\", \"glue\", \"lambda\"],\n",
    "    \"gcp\": [\"gcp\", \"google cloud\", \"bigquery\", \"cloud storage\"],\n",
    "    \"azure\": [\"azure\", \"synapse\", \"databricks\"],\n",
    "\n",
    "    # ---------------- Data Engineering ----------------\n",
    "    \"etl\": [\"etl\", \"elt\", \"data pipeline\"],\n",
    "    \"airflow\": [\"airflow\"],\n",
    "    \"dbt\": [\"dbt\"],\n",
    "    \"snowflake\": [\"snowflake\"],\n",
    "\n",
    "    # ---------------- MLOps / Deployment ----------------\n",
    "    \"docker\": [\"docker\"],\n",
    "    \"kubernetes\": [\"kubernetes\", \"k8s\"],\n",
    "    \"mlflow\": [\"mlflow\"],\n",
    "    \"fastapi\": [\"fastapi\"],\n",
    "    \"flask\": [\"flask\"],\n",
    "    \"streamlit\": [\"streamlit\"],\n",
    "\n",
    "    # ---------------- Statistics ----------------\n",
    "    \"statistics\": [\n",
    "        \"statistics\", \"statistical\", \"hypothesis testing\",\n",
    "        \"regression\", \"anova\", \"probability\"\n",
    "    ],\n",
    "\n",
    "    # ---------------- Version Control ----------------\n",
    "    \"git\": [\"git\", \"github\", \"gitlab\"],\n",
    "\n",
    "    # ---------------- APIs ----------------\n",
    "    \"api\": [\"api\", \"rest api\"],\n",
    "\n",
    "    # ---------------- Linux ----------------\n",
    "    \"linux\": [\"linux\", \"unix\"],    \n",
    "\n",
    "}\n",
    "SKILL_COLUMNS = [f\"skill_{name}\" for name in SKILLS]\n",
    "\n",
    "\n",
    "def normalize_province_code(value) -> str:\n",
    "    text = str(value).strip()\n",
    "    if text.isdigit():\n",
    "        number = int(text)\n",
    "        if number <= 0:\n",
    "            raise ValueError(f\"Province must be positive, got: {value}\")\n",
    "        return f\"{number:02d}\"\n",
    "    raise ValueError(f\"Invalid province code: {value}\")\n",
    "\n",
    "\n",
    "def normalize_for_match(text: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\", \" \", text.lower()).strip()\n",
    "\n",
    "\n",
    "def normalize_for_skill_match(text: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\", \" \", text.lower()).strip()\n",
    "\n",
    "\n",
    "def keyword_match_groups_from_query(keyword: str) -> list[list[str]]:\n",
    "    term_variants = {\n",
    "        \"data\": [\"data\"],\n",
    "        \"scientist\": [\"scientist\", \"science\", \"scien\", \"scient\"],\n",
    "        \"science\": [\"science\", \"scientist\", \"scien\", \"scient\"],\n",
    "        \"engineer\": [\"engineer\", \"engineering\", \"eng\"],\n",
    "        \"analyst\": [\"analyst\", \"analytics\", \"analysis\"],\n",
    "        \"developer\": [\"developer\", \"development\", \"dev\"],\n",
    "    }\n",
    "\n",
    "    tokens = [token for token in normalize_for_match(keyword).split() if token]\n",
    "    groups = []\n",
    "\n",
    "    for token in tokens:\n",
    "        if token in term_variants:\n",
    "            groups.append(term_variants[token])\n",
    "        else:\n",
    "            groups.append([token])\n",
    "\n",
    "    return groups\n",
    "\n",
    "\n",
    "def title_matches_keyword(title: str, keyword_groups: list[list[str]]) -> bool:\n",
    "    if not keyword_groups:\n",
    "        return True\n",
    "\n",
    "    title_norm = normalize_for_match(title)\n",
    "    return all(any(variant in title_norm for variant in group) for group in keyword_groups)\n",
    "\n",
    "\n",
    "def variant_matches_text(variant: str, normalized_text: str) -> bool:\n",
    "    variant_norm = normalize_for_skill_match(variant)\n",
    "    if not variant_norm:\n",
    "        return False\n",
    "    pattern = rf\"(?<![a-z0-9]){re.escape(variant_norm).replace(r'\\\\ ', r'\\\\s+')}(?![a-z0-9])\"\n",
    "    return re.search(pattern, normalized_text) is not None\n",
    "\n",
    "\n",
    "def extract_skills(text: str) -> dict:\n",
    "    normalized_text = normalize_for_skill_match(text)\n",
    "    matched = []\n",
    "\n",
    "    for skill_name, variants in SKILLS.items():\n",
    "        if any(variant_matches_text(variant, normalized_text) for variant in variants):\n",
    "            matched.append(skill_name)\n",
    "\n",
    "    skill_flags = {f\"skill_{name}\": int(name in matched) for name in SKILLS}\n",
    "\n",
    "    return {\n",
    "        \"matched_skills\": \"|\".join(matched),\n",
    "        \"matched_skill_count\": len(matched),\n",
    "        **skill_flags,\n",
    "    }\n",
    "\n",
    "\n",
    "def normalize_jobthai_detail_url(job_url: str) -> str:\n",
    "    if not job_url:\n",
    "        return \"\"\n",
    "\n",
    "    parsed = urlparse(job_url)\n",
    "    path = parsed.path\n",
    "\n",
    "    path = path.replace(\"/th/company/job/\", \"/th/job/\")\n",
    "    path = path.replace(\"/company/job/\", \"/job/\")\n",
    "\n",
    "    return urlunparse((parsed.scheme, parsed.netloc, path, \"\", \"\", \"\"))\n",
    "\n",
    "\n",
    "def update_query_in_url(url: str, **params) -> str:\n",
    "    parsed = urlparse(url)\n",
    "    query = parse_qs(parsed.query)\n",
    "\n",
    "    for key, value in params.items():\n",
    "        query[key] = [str(value)]\n",
    "\n",
    "    new_query = urlencode(query, doseq=True)\n",
    "    return urlunparse((parsed.scheme, parsed.netloc, parsed.path, parsed.params, new_query, parsed.fragment))\n",
    "\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "\n",
    "def extract_salary(text: str) -> str:\n",
    "    patterns = [\n",
    "        r\"\\d[\\d,\\s]*\\s*-\\s*\\d[\\d,\\s]*\\s*บาท\",\n",
    "        r\"\\d[\\d,\\s]*\\s*บาท\",\n",
    "        r\"ตามโครงสร้างบริษัทฯ\",\n",
    "        r\"ตามประสบการณ์\",\n",
    "        r\"ตามตกลง\",\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            return clean_text(match.group(0))\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def extract_posted_date(text: str) -> str:\n",
    "    match = re.search(r\"\\b\\d{1,2}\\s+[ก-๙A-Za-z\\.]+\\s+\\d{2}\\b\", text)\n",
    "    return clean_text(match.group(0)) if match else \"\"\n",
    "\n",
    "\n",
    "def pick_text(parent, selectors: list[str]) -> str:\n",
    "    for selector in selectors:\n",
    "        element = parent.select_one(selector)\n",
    "        if element:\n",
    "            text = clean_text(element.get_text(\" \", strip=True))\n",
    "            if text:\n",
    "                return text\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def guess_location(lines: list[str], title: str, company: str, salary: str) -> str:\n",
    "    priority_keywords = [\"เขต\", \"กรุงเทพ\", \"จังหวัด\", \"อำเภอ\", \"อ.\", \"ต.\"]\n",
    "    transit_keywords = [\"BTS\", \"MRT\", \"SRT\", \"BRT\", \"Airport Rail Link\"]\n",
    "\n",
    "    for line in lines:\n",
    "        if line in {title, company, salary}:\n",
    "            continue\n",
    "        if any(keyword in line for keyword in priority_keywords):\n",
    "            return line\n",
    "\n",
    "    for line in lines:\n",
    "        if line in {title, company, salary}:\n",
    "            continue\n",
    "        if any(keyword in line for keyword in transit_keywords):\n",
    "            return line\n",
    "\n",
    "    if salary and salary in lines:\n",
    "        salary_idx = lines.index(salary)\n",
    "        for idx in range(salary_idx - 1, -1, -1):\n",
    "            candidate = lines[idx]\n",
    "            if candidate not in {title, company}:\n",
    "                return candidate\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def parse_card_from_title(title_node, page_num: int, keyword: str) -> dict:\n",
    "    title = clean_text(title_node.get_text(\" \", strip=True))\n",
    "\n",
    "    anchor = title_node.find_parent(\"a\", href=True)\n",
    "    href = anchor.get(\"href\", \"\") if anchor else \"\"\n",
    "    job_url = href if href.startswith(\"http\") else f\"https://www.jobthai.com{href}\"\n",
    "    job_url = normalize_jobthai_detail_url(job_url)\n",
    "\n",
    "    card = anchor if anchor is not None else title_node\n",
    "\n",
    "    company = pick_text(card, [\n",
    "        'span[id^=\"job-list-company-name-\"]',\n",
    "        'h2.ohgq7e-0.enAWkF',\n",
    "    ])\n",
    "\n",
    "    location = pick_text(card, [\n",
    "        \"h3#location-text\",\n",
    "        \"h3.location-text\",\n",
    "    ])\n",
    "\n",
    "    salary = pick_text(card, [\n",
    "        \"span.salary-text\",\n",
    "        \"div.msklqa-20\",\n",
    "        \"div.msklqa-17\",\n",
    "    ])\n",
    "\n",
    "    posted_date = pick_text(card, [\n",
    "        \"span.msklqa-9\",\n",
    "    ])\n",
    "\n",
    "    raw_lines = [clean_text(x) for x in card.get_text(\"\\n\", strip=True).splitlines() if clean_text(x)]\n",
    "    raw_text = clean_text(\" \".join(raw_lines))\n",
    "\n",
    "    if not salary:\n",
    "        salary = extract_salary(raw_text)\n",
    "    if not posted_date:\n",
    "        posted_date = extract_posted_date(raw_text)\n",
    "    if not location:\n",
    "        location = guess_location(raw_lines, title=title, company=company, salary=salary)\n",
    "\n",
    "    return {\n",
    "        \"keyword\": keyword,\n",
    "        \"page\": page_num,\n",
    "        \"job_title\": title,\n",
    "        \"company\": company,\n",
    "        \"location\": location,\n",
    "        \"salary\": salary,\n",
    "        \"posted_date\": posted_date,\n",
    "        \"job_url\": job_url,\n",
    "        \"raw_text\": raw_text,\n",
    "    }\n",
    "\n",
    "\n",
    "def extract_detail_from_job_page(job_url: str, headers: dict) -> dict:\n",
    "    base_detail = {\n",
    "        \"province_code\": \"\",\n",
    "        \"province_name\": \"\",\n",
    "        \"job_detail_text\": \"\",\n",
    "        \"job_qualification_text\": \"\",\n",
    "        \"matched_skills\": \"\",\n",
    "        \"matched_skill_count\": 0,\n",
    "        **{column: 0 for column in SKILL_COLUMNS},\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(job_url, headers=headers, timeout=30)\n",
    "        response.raise_for_status()\n",
    "    except Exception:\n",
    "        return base_detail\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    province_code = \"\"\n",
    "    province_name = \"\"\n",
    "    for anchor in soup.select('a[href*=\"province=\"]'):\n",
    "        tag = anchor.select_one('h3[id^=\"job-detail-tag-\"]')\n",
    "        if not tag:\n",
    "            continue\n",
    "\n",
    "        href = anchor.get(\"href\", \"\")\n",
    "        name = clean_text(tag.get_text(\" \", strip=True))\n",
    "        if not href or not name:\n",
    "            continue\n",
    "\n",
    "        province_value = parse_qs(urlparse(href).query).get(\"province\", [\"\"])[0]\n",
    "        if not province_value or not province_value.isdigit():\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            province_code = normalize_province_code(province_value)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "        province_name = name\n",
    "        break\n",
    "\n",
    "    jd_node = soup.select_one(\"span#job-detail\")\n",
    "    job_detail_text = clean_text(jd_node.get_text(\"\\n\", strip=True)) if jd_node else \"\"\n",
    "\n",
    "    qualification_node = soup.select_one(\"#job-properties-wrapper\")\n",
    "    job_qualification_text = clean_text(qualification_node.get_text(\" \", strip=True)) if qualification_node else \"\"\n",
    "\n",
    "    combined_text = \" \".join([text for text in [job_detail_text, job_qualification_text] if text])\n",
    "    skill_info = extract_skills(combined_text)\n",
    "\n",
    "    return {\n",
    "        \"province_code\": province_code,\n",
    "        \"province_name\": province_name,\n",
    "        \"job_detail_text\": job_detail_text,\n",
    "        \"job_qualification_text\": job_qualification_text,\n",
    "        **skill_info,\n",
    "    }\n",
    "\n",
    "\n",
    "def scrape_jobthai_all_locations(\n",
    "    search_url: str,\n",
    "    max_pages: int = 10,\n",
    "    sleep_seconds: float = 1.0,\n",
    "    detail_sleep_seconds: float = 0.5,\n",
    ") -> pd.DataFrame:\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\",\n",
    "        \"Accept-Language\": \"th-TH,th;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
    "    }\n",
    "\n",
    "    keyword = parse_qs(urlparse(search_url).query).get(\"keyword\", [\"\"])[0]\n",
    "    keyword_groups = keyword_match_groups_from_query(keyword)\n",
    "\n",
    "    all_rows = []\n",
    "    seen_urls = set()\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"[Search] Starting page crawl: max_pages={max_pages}\")\n",
    "\n",
    "    for page_num in range(1, max_pages + 1):\n",
    "        page_url = update_query_in_url(search_url, page=page_num)\n",
    "        print(f\"[Search] Page {page_num}/{max_pages} -> request\")\n",
    "\n",
    "        response = requests.get(page_url, headers=headers, timeout=30)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        if \"nodata=true\" in response.url.lower():\n",
    "            print(f\"[Search] Page {page_num}/{max_pages} -> nodata=true, stopping\")\n",
    "            break\n",
    "\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        title_nodes = soup.select('h2[id^=\"job-card-item-\"]')\n",
    "        print(f\"[Search] Page {page_num}/{max_pages} -> found cards: {len(title_nodes)}\")\n",
    "\n",
    "        page_rows = []\n",
    "        for title_node in title_nodes:\n",
    "            row = parse_card_from_title(\n",
    "                title_node,\n",
    "                page_num=page_num,\n",
    "                keyword=keyword,\n",
    "            )\n",
    "            if not row[\"job_url\"]:\n",
    "                continue\n",
    "            if not title_matches_keyword(row[\"job_title\"], keyword_groups):\n",
    "                continue\n",
    "            if row[\"job_url\"] in seen_urls:\n",
    "                continue\n",
    "\n",
    "            seen_urls.add(row[\"job_url\"])\n",
    "            page_rows.append(row)\n",
    "\n",
    "        if not page_rows:\n",
    "            print(f\"[Search] Page {page_num}/{max_pages} -> no keyword matches, stopping\")\n",
    "            break\n",
    "\n",
    "        all_rows.extend(page_rows)\n",
    "        print(\n",
    "            f\"[Search] Page {page_num}/{max_pages} -> kept {len(page_rows)} | cumulative={len(all_rows)}\"\n",
    "        )\n",
    "\n",
    "        if sleep_seconds > 0:\n",
    "            time.sleep(sleep_seconds)\n",
    "\n",
    "    total_details = len(all_rows)\n",
    "    print(f\"[Detail] Starting detail extraction for {total_details} jobs\")\n",
    "\n",
    "    for index, row in enumerate(all_rows, start=1):\n",
    "        detail_info = extract_detail_from_job_page(row[\"job_url\"], headers=headers)\n",
    "        row.update(detail_info)\n",
    "\n",
    "        if total_details <= 50 or index % 10 == 0 or index == total_details:\n",
    "            percent = (index / total_details) * 100 if total_details else 100\n",
    "            print(f\"[Detail] {index}/{total_details} ({percent:.1f}%)\")\n",
    "\n",
    "        if detail_sleep_seconds > 0:\n",
    "            time.sleep(detail_sleep_seconds)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"[Done] Completed in {elapsed:.1f}s\")\n",
    "\n",
    "    df = pd.DataFrame(all_rows)\n",
    "\n",
    "    if not df.empty:\n",
    "        ordered_columns = [\n",
    "            \"keyword\",\n",
    "            \"province_code\",\n",
    "            \"province_name\",\n",
    "            \"page\",\n",
    "            \"job_title\",\n",
    "            \"company\",\n",
    "            \"location\",\n",
    "            \"salary\",\n",
    "            \"posted_date\",\n",
    "            \"job_url\",\n",
    "            \"raw_text\",\n",
    "            \"job_detail_text\",\n",
    "            \"job_qualification_text\",\n",
    "            \"matched_skills\",\n",
    "            \"matched_skill_count\",\n",
    "            *SKILL_COLUMNS,\n",
    "        ]\n",
    "        for column in ordered_columns:\n",
    "            if column not in df.columns:\n",
    "                df[column] = \"\" if column not in {\"matched_skill_count\", *SKILL_COLUMNS} else 0\n",
    "\n",
    "        df = df[ordered_columns].drop_duplicates(subset=[\"job_url\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "jobs_df = scrape_jobthai_all_locations(\n",
    "    SEARCH_URL,\n",
    "    max_pages=MAX_PAGES,\n",
    "    sleep_seconds=SLEEP_SECONDS,\n",
    "    detail_sleep_seconds=DETAIL_SLEEP_SECONDS,\n",
    ")\n",
    "print(f\"\\nTotal unique jobs: {len(jobs_df)}\")\n",
    "\n",
    "output_path = Path(OUTPUT_CSV)\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "jobs_df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"Saved CSV: {output_path.resolve()}\")\n",
    "\n",
    "jobs_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
